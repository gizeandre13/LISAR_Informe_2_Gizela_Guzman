{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71311464-4547-4906-ab5c-a79d01d88e7c",
   "metadata": {},
   "source": [
    "# ConstrucciÃ³n automatizada de modelos 3D de Ã¡rboles, a partir de datos LiDAR\n",
    "\n",
    "**Informe NÂ° 2 RADAR Y LIDAR**\n",
    "\n",
    "**Estudiante**: Gizela Andrea GuzmÃ¡n Lugo\n",
    "\n",
    "**Fecha**: 24/11/2025\n",
    "\n",
    "El flujo de trabajo aplicado en este proyecto tiene como objetivo la construcciÃ³n de modelos 3D de Ã¡rboles a partir de datos LiDAR, con fines de anÃ¡lisis geomÃ©trico y semÃ¡ntico. El proceso parte de una nube de puntos clasificada de manera preliminar, para extraer exclusivamente aquellos puntos correspondientes a vegetaciÃ³n. Sobre esta base filtrada, se ejecutan distintas etapas de segmentaciÃ³n, depuraciÃ³n,limpieza y, finalmente, modelado geomÃ©trico de Ã¡rboles.\n",
    "\n",
    "**ClasificaciÃ³n inicial del LiDAR**: El primer paso consiste en identificar y separar los puntos correspondientes a vegetaciÃ³n dentro de la nube original. Aunque esta clasificaciÃ³n suele ser aproximada, permite aislar ramas, follaje y troncos, eliminando elementos como suelo, edificaciones o vehÃ­culos.\n",
    "\n",
    "**SegmentaciÃ³n individual de Ã¡rboles**: Una vez aislados los puntos de vegetaciÃ³n, se aplica un proceso de segmentaciÃ³n espacial cuyo propÃ³sito es dividir la nube en subconjuntos, donde cada segmento representa idealmente un Ã¡rbol individual. Esta etapa es fundamental para pasar del nivel de vegetaciÃ³n general al nivel de objeto individual.\n",
    "\n",
    "**DepuraciÃ³n y limpieza de segmentos**: DespuÃ©s de segmentar los Ã¡rboles, los datos pueden contener errores de clasificaciÃ³n o puntos atÃ­picos. Se realiza entonces una limpieza por segmentaciÃ³n, filtrando ruido, puntos descolgados o valores extremos que podrÃ­an afectar el modelado o el anÃ¡lisis posterior.\n",
    "\n",
    "**Modelado geomÃ©trico de Ã¡rboles**: Los segmentos limpios se utilizan para reconstruir Ã¡rboles en diferentes niveles de detalle (LOD). Esto permite representar desde formas simplificadas como cilindros y prismas (LOD1), hasta estructuras mÃ¡s complejas como copas paramÃ©tricas o volÃºmenes ajustados a los datos reales (LOD2 o LOD3).\n",
    "\n",
    "Para el desarrollo de este trabajo se usan los datos de nubes de puntos disponibles abiertamente (Actueel Hoogtebestand Nederland -AHN3), en la plataforma holandesa de geodatos, Publieke Dienstverlening Op de Kaart (PDOK).\n",
    "\n",
    "Este trabajo es una implementaciÃ³n de de la lÃ­nea base presentada en [\\\"Automatic construction of 3D tree models in\n",
    "multiple levels of detail from airborne LiDAR data\\\"](https://repository.tudelft.nl/record/uuid:3e169fc7-5336-4742-ab9b-18c158637cfe), Geert Jan (Rob) de Groot, TU Delft - Architecture and the Built Environment, Master Thesis (2020).\n",
    "\n",
    "Repositorio Github: [\\\"TreeConstruction\\\"](https://github.com/RobbieG91/TreeConstruction/tree/master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada962f-eded-49d3-9daa-154bdadf6a4b",
   "metadata": {},
   "source": [
    "**Importacion de librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4ba6eb-d436-4cf2-9e3e-5324960f0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os          # Permite manejar rutas y archivos del sistema operativo\n",
    "import time        # Mide tiempos de ejecuciÃ³n\n",
    "import subprocess  # Ejecuta comandos externos del sistema \n",
    "import rasterio     # LibrerÃ­a especializada para leer, escribir y manejar datos raster \n",
    "import numpy as np # Manejo eficiente de arreglos numÃ©ricos, cÃ¡lculos matemÃ¡ticos y manipulaciÃ³n de matrices.\n",
    "import laspy       # Permite leer, modificar y escribir archivos LiDAR (.las y .laz)\n",
    "import math        # Proporciona funciones matemÃ¡ticas bÃ¡sicas (trigonometrÃ­a, potencia, logaritmos)\n",
    "from sklearn.preprocessing import StandardScaler  # Normaliza y escala valores numÃ©ricos \n",
    "from sklearn.cluster import DBSCAN               # Algoritmo de clustering \n",
    "from sklearn import linear_model                 # Proporciona modelos lineales como RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaca0f8-57f5-4f9b-82ff-3867a64208eb",
   "metadata": {},
   "source": [
    "**DefiniciÃ³n de ruta base y archivo LiDAR de entrada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d16681-c9f8-4dd5-ac51-0e9fbaa96205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta base donde se almacenan los datos del proyecto\n",
    "BASE_PATH = r\"D:\\MODELO_3D\\arboles\"\n",
    "\n",
    "# Nombre del archivo LiDAR original (crudo), que contiene los puntos XYZ, intensidad, retornos, etc.\n",
    "FILENAME  = \"Noordereiland.laz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da16a5-daf5-4766-90bb-38b7cd617b17",
   "metadata": {},
   "source": [
    "## 1. ClasificaciÃ³n inicial datos LiDAR\n",
    "\n",
    "La nube de puntos AHN3 utilizada ya contiene clases predefinidas, pero para este proyecto se trabaja con la clase sin clasificar, con el objetivo de extraer Ãºnicamente puntos de vegetaciÃ³n. Para ello, se realiza una reclasificaciÃ³n usando las caracterÃ­sticas espaciales X, Y y la altura normalizada, estimando la rugosidad local de los puntos. Los puntos con alta variabilidad en altura se consideran vegetaciÃ³n, mientras que los de baja variaciÃ³n corresponden a superficies planas (edificios, suelo, vehÃ­culos, etc.). AdemÃ¡s, se aplica un filtro por altura (>2 m) para eliminar rÃ¡pidamente objetos cercanos al suelo como coches, mobiliario urbano o ruido.\n",
    "\n",
    "Para este proceso se utiliza ``LAStools``, una suite especializada para el procesamiento de nubes de puntos LiDAR. La elecciÃ³n de esta herramienta se debe a su alta eficiencia, velocidad de procesamiento y fiabilidad. Como requiere de licencia para el procesamiento de nubes de puntos, se utiiza en modo demo.\n",
    "\n",
    "**Cambios al cÃ³digo original**\n",
    "\n",
    "El cÃ³digo fue adaptado para aprovechar las herramientas de LAStools en modo demo, ejecutando directamente los archivos .exe instalados en el computador. Estas aplicaciones fueron descargadas previamente desde la pÃ¡gina oficial y se invocan desde el script mediante llamadas al sistema, permitiendo procesar los datos LiDAR sin necesidad de instalar la librerÃ­a completa en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf336dc-a1fc-426e-918c-aa6c36822ccb",
   "metadata": {},
   "source": [
    "### ðŸ“Š 1.1 NormalizaciÃ³n alturas\n",
    "\n",
    "Se creo la funciÃ³n ``normalize_height``, la cual permite normalizar las alturas de un archivo LiDAR (.las o .laz) mediante la herramienta ``lasheight`` de LAStools, con el fin de recalcular la altura de cada punto respecto al terreno (altura relativa) y almacenarla como atributo adicional. Esto es fundamental para tareas de anÃ¡lisis de vegetaciÃ³n de objetos 3D, ya que los modelos basados en altura normalizada permiten identificar los Ã¡rboles. La funciÃ³n implementa un procesamiento automatizado en Python, verificando la disponibilidad de los archivos, construyendo dinÃ¡micamente la ruta de entrada y salida, y ejecutando el comando desde el sistema mediante subprocess.run. Finalmente, genera un nuevo archivo con sufijo _height_veg.laz, que incluye la altura normalizada como atributo, listo para etapas posteriores de segmentaciÃ³n y modelado 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84451d6d-0220-417e-84b6-e0333a03349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_height(path, filename_laz):\n",
    "    \"\"\"\n",
    "    Normaliza alturas con lasheight64 (LAStools).\n",
    "    - path: carpeta base donde estÃ¡n los datos.\n",
    "    - filename_laz: nombre del archivo .las/.laz original,\n",
    "    \"\"\"\n",
    "    # Ruta completa del archivo de entrada\n",
    "    in_file = os.path.join(path, filename_laz)\n",
    "    base_name, ext = os.path.splitext(filename_laz)\n",
    "    out_file = os.path.join(path, base_name + \"_height_veg.laz\")\n",
    "\n",
    "    # Ruta al ejecutable \n",
    "    exe = r\"D:\\MODELO_3D\\arboles\\LAStools\\bin\\lasheight64.exe\"\n",
    "\n",
    "    # Comando de ejecucciÃ³n como lista, con -demo\n",
    "    cmd = [\n",
    "        exe,   # Ejecutable de lasheight64\n",
    "        \"-demo\",# Modo Demo\n",
    "        \"-i\", in_file,\n",
    "        \"-o\", out_file,\n",
    "        \"-store_precise_as_extra_bytes\", # Guarda alturas normalizadas como extra bytes (mayor precisiÃ³n)\n",
    "    ]\n",
    "    # Muestra el comando antes de ejecutar\n",
    "    print(\"COMANDO:\", cmd)\n",
    "\n",
    "    # Ejecutar y ver mensajes\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    # Mostrar resultados de ejecuciÃ³n\n",
    "    print(\"RETURN CODE:\", result.returncode)\n",
    "    print(\"STDOUT:\\n\", result.stdout)\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "    \n",
    "    # Devuelve la ruta del nuevo archivo\n",
    "    return out_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ae3f847-587b-44f5-a95d-067788661f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMANDO: ['D:\\\\MODELO_3D\\\\arboles\\\\LAStools\\\\bin\\\\lasheight64.exe', '-demo', '-i', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland.laz', '-o', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg.laz', '-store_precise_as_extra_bytes']\n",
      "RETURN CODE: 1\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " Please note that LAStools is not \"free\" (see https://rapidlasso.de/license)\n",
      "contact 'info@rapidlasso.de' to clarify licensing terms if needed.\n",
      "WARNING: unlicensed. over 1.5 million points. output slightly distorted.\n",
      "         tiny xyz noise. points permuted. intensity, gps_time & point_source_ID zeroed.\n",
      "done with 'D:\\MODELO_3D\\arboles\\Noordereiland_height_veg.laz'. total time 8.417 sec.\n",
      "\n",
      "NORMALIZED: D:\\MODELO_3D\\arboles\\Noordereiland_height_veg.laz existe? True\n"
     ]
    }
   ],
   "source": [
    "# 1) Normalizar alturas\n",
    "normalized = normalize_height(BASE_PATH, FILENAME)\n",
    "print(\"NORMALIZED:\", normalized, \"existe?\", os.path.exists(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec40c99-e6d5-4222-aba3-dc002908fd57",
   "metadata": {},
   "source": [
    "### ðŸŒ¿ 1.2 ClasificaciÃ³n puntos\n",
    "\n",
    "En esta etapa se emplea `lasclassify64` (LAStools) para reclasificar los puntos del archivo normalizado (*_height_veg.laz*).  \n",
    "\n",
    "La herramienta utiliza la altura normalizada y medidas de rugosidad local para separar vegetaciÃ³n de superficies planas como suelo y edificaciones. \n",
    "\n",
    "Se definen umbrales para:\n",
    "- `-ground_offset 2.0`: filtrar objetos cercanos al terreno (â‰¤ 2 m).\n",
    "- `-planar 0.1`: identificar superficies casi planas (tejados, pavimento).\n",
    "- `-rugged 0.4`: identificar vecindades rugosas asociadas a copas de Ã¡rboles.  \n",
    "\n",
    "El archivo de salida *_classified.laz* contiene los puntos ya clasificados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34c0b523-f4d7-4ce0-bf0d-0e58624a87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_points(path, normalized_file):\n",
    "    \"\"\"\n",
    "    Clasifica puntos usando lasclassify64.\n",
    "    - normalized_file: ruta COMPLETA al archivo *_height_veg.laz devuelto por normalize_height\n",
    "    \"\"\"\n",
    "    # El archivo de entrada es el mismo que devuelve normalize_height\n",
    "    in_file = normalized_file\n",
    "    \n",
    "    # salida: mismo path + sufijo _classified.laz\n",
    "    base_noext, ext = os.path.splitext(in_file)\n",
    "    out_file = base_noext + \"_classified.laz\"\n",
    "    \n",
    "    # Ruta al ejecutable de lasclassify64\n",
    "    exe = r\"D:\\MODELO_3D\\arboles\\LAStools\\bin\\lasclassify64.exe\"\n",
    "\n",
    "    print(\"IN FILE (classify):\", in_file, \"existe?\", os.path.exists(in_file))\n",
    "    print(\"EXE (classify):\", exe, \"existe?\", os.path.exists(exe))\n",
    "    print(\"OUT FILE (classify):\", out_file)\n",
    "\n",
    "     # ConstrucciÃ³n del comando para lasclassify64\n",
    "    cmd = [\n",
    "        exe, # Ejecutable de lasclassify64\n",
    "        \"-demo\",                   \n",
    "        \"-i\", in_file,\n",
    "        \"-o\", out_file,\n",
    "        \"-height_in_attribute\", \"0\", #Indica que la altura normalizada estÃ¡ almacenada en el atributo extra 0\n",
    "        \"-ground_offset\", \"2.0\", # Desplazamiento del terreno: puntos por debajo de 2 m se consideran cercanos al suelo\n",
    "        \"-planar\", \"0.1\", # Umbral para identificar superficies planas (baja variaciÃ³n vertical)\n",
    "        \"-rugged\", \"0.4\", # Umbral para identificar vecindades rugosas (alta variaciÃ³n vertical, tÃ­pico de vegetaciÃ³n)\n",
    "    ]\n",
    "    # Mostrar el comando para verificaciÃ³n\n",
    "    print(\"COMANDO classify:\", cmd)\n",
    "    \n",
    "    # Ejecuta el comando y captura salida y posibles errores\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    print(\"RETURN CODE:\", result.returncode)\n",
    "    print(\"STDOUT:\\n\", result.stdout)\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "    \n",
    "    # Devuelve la ruta del archivo clasificado\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "153f6a3d-d3e9-4561-a807-ed42bf5facc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN FILE (classify): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg.laz existe? True\n",
      "EXE (classify): D:\\MODELO_3D\\arboles\\LAStools\\bin\\lasclassify64.exe existe? True\n",
      "OUT FILE (classify): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified.laz\n",
      "COMANDO classify: ['D:\\\\MODELO_3D\\\\arboles\\\\LAStools\\\\bin\\\\lasclassify64.exe', '-demo', '-i', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg.laz', '-o', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg_classified.laz', '-height_in_attribute', '0', '-ground_offset', '2.0', '-planar', '0.1', '-rugged', '0.4']\n",
      "RETURN CODE: 1\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " Please note that LAStools is not \"free\" (see https://rapidlasso.de/license)\n",
      "contact 'info@rapidlasso.de' to clarify licensing terms if needed.\n",
      "WARNING: unlicensed. over 1.5 million points. output slightly distorted. tiny xyz noise. points permuted. intensity, gps_time, user_data\n",
      "and point_source_ID zeroed.\n",
      "done with 'D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified.laz'. total time 30.813 sec.\n",
      "\n",
      "CLASSIFIED: D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified.laz existe? True\n"
     ]
    }
   ],
   "source": [
    "# 2) Clasificar\n",
    "classified = classify_points(BASE_PATH, normalized)\n",
    "print(\"CLASSIFIED:\", classified, \"existe?\", os.path.exists(classified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25adf6d9-723b-4a2e-bd74-79d45f4c9ced",
   "metadata": {},
   "source": [
    "### ðŸŒ²1.3 Filtrado de vegetaciÃ³n alta\n",
    "\n",
    "Una vez clasificados los puntos LiDAR, se aplica un filtrado para conservar Ãºnicamente la vegetaciÃ³n (clase 5). Para ello, se utiliza `las2las`, una herramienta de LAStools que permite extraer o eliminar clases especÃ­ficas de un archivo LAS/LAZ.\n",
    "\n",
    "AquÃ­ filtramos **solo la clase 5 (High Vegetation)**, correspondiente a Ã¡rboles y arbustos altos, generando el archivo `*_ONLYveg.laz`, que servirÃ¡ como base para los procesos de segmentaciÃ³n y modelado 3D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "645268f9-78aa-4ad8-8665-642afcc7697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_veg(path, classified_file):\n",
    "    \"\"\"\n",
    "    Filtra solo la vegetaciÃ³n (clase 5) usando las2las64.\n",
    "    - classified_file: ruta COMPLETA al archivo *_classified.laz\n",
    "    \"\"\"\n",
    "    # Archivo de entrada: resultado del paso anterior (clasificaciÃ³n)\n",
    "    in_file = classified_file\n",
    "    # ConstrucciÃ³n del nombre del archivo de salida\n",
    "    base_noext, ext = os.path.splitext(in_file)\n",
    "    out_file = base_noext + \"_ONLYveg.laz\"\n",
    "     \n",
    "    # Ruta al ejecutable de las2las\n",
    "    exe = r\"D:\\MODELO_3D\\arboles\\LAStools\\bin\\las2las64.exe\"  \n",
    "    \n",
    "    # Verificaciones para depuraciÃ³n\n",
    "    print(\"IN FILE (filter):\", in_file, \"existe?\", os.path.exists(in_file))\n",
    "    print(\"EXE (filter):\", exe, \"existe?\", os.path.exists(exe))\n",
    "    print(\"OUT FILE (filter):\", out_file)\n",
    "    \n",
    "    # ConstrucciÃ³n del comando de filtrado\n",
    "    cmd = [\n",
    "        exe,\n",
    "        \"-i\", in_file,       \n",
    "        \"-o\", out_file,\n",
    "        \"-keep_class\", \"5\",   # vegetaciÃ³n alta\n",
    "    ]\n",
    "    \n",
    "    # Mostrar el comando para verificaciones\n",
    "    print(\"COMANDO filter:\", cmd)\n",
    "    \n",
    "    # Ejecutar el comando y capturar mensajes\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    print(\"RETURN CODE:\", result.returncode)\n",
    "    print(\"STDOUT:\\n\", result.stdout)\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "    \n",
    "    # Devolver la ruta del archivo resultante\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70c666fb-0385-437a-871c-1e4543fe3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN FILE (filter): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified.laz existe? True\n",
      "EXE (filter): D:\\MODELO_3D\\arboles\\LAStools\\bin\\las2las64.exe existe? True\n",
      "OUT FILE (filter): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg.laz\n",
      "COMANDO filter: ['D:\\\\MODELO_3D\\\\arboles\\\\LAStools\\\\bin\\\\las2las64.exe', '-i', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg_classified.laz', '-o', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg_classified_ONLYveg.laz', '-keep_class', '5']\n",
      "RETURN CODE: 0\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " \n",
      "FILTERED: D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg.laz existe? True\n"
     ]
    }
   ],
   "source": [
    "# 3) Filtrar vegetaciÃ³n\n",
    "filtered = filter_veg(BASE_PATH, classified)\n",
    "print(\"FILTERED:\", filtered, \"existe?\", os.path.exists(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7173d4c-6a0f-45a5-87a6-19e18b46abc3",
   "metadata": {},
   "source": [
    "## 2. SegmentaciÃ³n individual de Ã¡rboles\n",
    "\n",
    "La segmentaciÃ³n de la nube de puntos filtrada (vegetaciÃ³n alta) se realiza mediante un enfoque basado en el algoritmo **Watershed**, implementado en el mÃ³dulo *Watershed Segmentation* de **System for Automated Geoscientific Analyses (SAGA GIS)**. Este procedimiento permite identificar y separar copas individuales a partir de las variaciones locales de altura, detectando los mÃ¡ximos locales (posibles Ã¡pices de los Ã¡rboles) y delimitando sus zonas de influencia.\n",
    "\n",
    "El flujo operativo se articula mediante las siguientes etapas:\n",
    "\n",
    "1ï¸âƒ£ **GeneraciÃ³n del Modelo Digital del Dosel (CHM)**: A partir de la nube LiDAR clasificada y normalizada, se construye un Modelo Digital del Dosel (CHM), calculando la altura mÃ¡xima de los retornos en cada celda. Este raster representa la estructura vertical del dosel arbÃ³reo y constituye la base para identificar las copas individuales.\n",
    "\n",
    "2ï¸âƒ£ **SegmentaciÃ³n de copas mediante Watershed (SAGA GIS)**: Sobre el CHM se ejecuta el algoritmo Watershed, que interpreta el raster como una superficie topogrÃ¡fica invertida. Los mÃ¡ximos locales se reconocen como centros potenciales de copas, mientras que las lÃ­neas divisorias entre ellos definen los lÃ­mites de cada Ã¡rbol. Como resultado, se obtiene un raster segmentado donde cada pÃ­xel contiene un ID Ãºnico asociado a una copa.\n",
    "\n",
    "3ï¸âƒ£ **Transferencia de los segmentos a la nube de puntos**: Finalmente, el raster segmentado se superpone con la nube LiDAR. Mediante operaciones de intersecciÃ³n espacial, a cada punto se le asigna el ID del segmento (copa) correspondiente al pÃ­xel donde se ubica. De esta forma, se genera una nube de puntos segmentada Ã¡rbol por Ã¡rbol, conservando tanto la estructura 3D como la identidad de cada copa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd68b6aa-0d6c-4e7f-87fe-36ad5bbf3392",
   "metadata": {},
   "source": [
    "### ðŸŸ© 2.1 GeneraciÃ³n del Modelo Digital del Dosel (CHM)\n",
    "Dado que el algoritmo de Watershed opera sobre superficies continuas, es necesario convertir previamente la nube de puntos a un raster. A partir de la nube de puntos clasificada como vegetaciÃ³n se crea un raster que representa las alturas mÃ¡ximas del dosel arbÃ³reo. Generando un Modelo Digital del Dosel (CHM), este CHM (Canopy Height Model) captura la estructura vertical de las copas y permite detectar patrones espaciales, como cÃºspides, bordes y Ã¡reas de transiciÃ³n entre Ã¡rboles. \n",
    "\n",
    "Para este propÃ³sito se emplea la herramienta `lasgrid` de LAStools, utilizando como atributo de elevaciÃ³n la altura normalizada previamente calculada. Se usa la opciÃ³n `-highest`, que permite obtener un CHM representando las alturas mÃ¡ximas de la vegetaciÃ³n por celda.  El raster resultante corresponde a un CHM con una resoluciÃ³n espacial de 0.75 metros, el cual ofrece un equilibrio adecuado entre nivel de detalle y eficiencia computacional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09c97776-d182-4f5b-a5de-36aa3edd485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dem(path, veg_file):\n",
    "    \"\"\"\n",
    "    Crea un raster (DEM/DSM) de 0.75 m usando lasgrid64.\n",
    "    - veg_file: ruta COMPLETA al archivo *_ONLYveg.laz (o el que quieras rasterizar)\n",
    "    \"\"\"\n",
    "    # Archivo de entrada: nube de puntos filtrada\n",
    "    in_file = veg_file\n",
    "    # Definir archivo de salida con sufijo indicativo del DEM\n",
    "    base_noext, ext = os.path.splitext(in_file)\n",
    "    out_file = base_noext + \"_DEM0_75.tif\"\n",
    "    \n",
    "    # Ruta al ejecutable de lasgrid64\n",
    "    exe = r\"D:\\MODELO_3D\\arboles\\LAStools\\bin\\lasgrid64.exe\"\n",
    "    \n",
    "    # Comprobaciones bÃ¡sicas\n",
    "    print(\"IN FILE (grid):\", in_file, \"existe?\", os.path.exists(in_file))\n",
    "    print(\"EXE (grid):\", exe, \"existe?\", os.path.exists(exe))\n",
    "    print(\"OUT FILE (grid):\", out_file)\n",
    "    \n",
    "    # ConstrucciÃ³n del comando para crear el raster\n",
    "    cmd = [\n",
    "        exe,\n",
    "        \"-demo\",               \n",
    "        \"-i\", in_file,\n",
    "        \"-o\", out_file,\n",
    "        \"-attribute\", \"0\",     # altura normalizada en atributo 0\n",
    "        \"-step\", \"0.75\",       # tamaÃ±o de celda (m)\n",
    "        \"-highest\",            # DSM/canopy (mÃ¡ximo valor en la celda)\n",
    "    ]\n",
    "\n",
    "    print(\"COMANDO grid:\", cmd)\n",
    "\n",
    "    # Ejecutar y capturar salida\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(\"RETURN CODE:\", result.returncode)\n",
    "    print(\"STDOUT:\\n\", result.stdout)\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "    \n",
    "    # Retornar ruta del archivo generado\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c297290-d545-4b70-93b0-dcea31e87eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN FILE (grid): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg.laz existe? True\n",
      "EXE (grid): D:\\MODELO_3D\\arboles\\LAStools\\bin\\lasgrid64.exe existe? True\n",
      "OUT FILE (grid): D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg_DEM0_75.tif\n",
      "COMANDO grid: ['D:\\\\MODELO_3D\\\\arboles\\\\LAStools\\\\bin\\\\lasgrid64.exe', '-demo', '-i', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg_classified_ONLYveg.laz', '-o', 'D:\\\\MODELO_3D\\\\arboles\\\\Noordereiland_height_veg_classified_ONLYveg_DEM0_75.tif', '-attribute', '0', '-step', '0.75', '-highest']\n",
      "RETURN CODE: 0\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " Please note that LAStools is not \"free\" (see https://rapidlasso.de/license)\n",
      "contact 'info@rapidlasso.de' to clarify licensing terms if needed.\n",
      "took 0.073 sec. done with 'D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg_DEM0_75.tif'.\n",
      "\n",
      "DEM: D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg_DEM0_75.tif existe? True\n"
     ]
    }
   ],
   "source": [
    "# Crear DEM / raster\n",
    "dem = create_dem(BASE_PATH, filtered)\n",
    "print(\"DEM:\", dem, \"existe?\", os.path.exists(dem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e30e47-f7f0-4e6d-b7a1-b97704bcaaec",
   "metadata": {},
   "source": [
    "### ðŸŒ2.2  SegmentaciÃ³n Watershed\n",
    "\n",
    "Para separar Ã¡rboles individuales a partir del Modelo Digital del Dosel (CHM), se aplicÃ³ el algoritmo Watershed, disponible en el mÃ³dulo Watershed Segmentation de SAGA GIS. Este mÃ©todo interpreta el CHM como una superficie topogrÃ¡fica, donde las cÃºspides o mÃ¡ximos locales representan los Ã¡pices de las copas, mientras que los lÃ­mites naturales entre Ã¡rboles se identifican como lÃ­neas divisorias de drenaje.\n",
    "\n",
    "Mediante el enfoque de cuencas hidrogrÃ¡ficas, Watershed detecta y delimita cada copa de forma automÃ¡tica, asignÃ¡ndole un identificador Ãºnico (ID de segmento) en formato raster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033efc87-6333-49dc-9021-3984db8fc4dc",
   "metadata": {},
   "source": [
    "### ðŸŒ€ 2.3 Transferencia de los segmentos a la nube de puntos:\n",
    "\n",
    "Una vez segmentado el Modelo Digital del Dosel (CHM) mediante Watershed en SAGA, cada pÃ­xel del raster tiene asignado un ID Ãºnico que representa una copa o grupo de copas. Ahora es el momento de asignar de nuevo los segmentos creados con el rÃ¡ster a la nube de puntos. Para ello se transfiere esa informaciÃ³n de segmentaciÃ³n desde el raster hacia la nube de puntos, de forma que cada punto LiDAR reciba el ID del Ã¡rbol al que pertenece.\n",
    "\n",
    "Para ello se llevan a cabo los siguientes pasos:\n",
    "\n",
    "1. Se leen los puntos LiDAR (X, Y, Z) y el raster segmentado.\n",
    "2. Se transforma cada coordenada (X, Y) a la posiciÃ³n (fila, columna) del raster.\n",
    "3. Se extrae el **SegmentID** correspondiente a ese pÃ­xel.\n",
    "4. Se asigna a cada punto el SegmentID como un nuevo atributo.\n",
    "5. Se guarda el nuevo archivo LAZ con los IDs por Ã¡rbol.\n",
    "\n",
    "El resultado es una **nube LiDAR segmentada por Ã¡rbol individual**, lista para extracciÃ³n de mÃ©tricas y modelado 3D.\n",
    "\n",
    "**Cambios al cÃ³digo original**\n",
    "\n",
    "Para transferir esta segmentaciÃ³n de vuelta a la nube de puntos, el autor utilizÃ³ el motor de manipulaciÃ³n de caracterÃ­sticas de FME, especÃ­ficamente mediante el transformador PointCloudOnRaster; mientras que en esta implementaciÃ³n se realizÃ³ el mismo procedimiento conceptual mediante una rutina en Python, evitando el uso de herramientas externas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23cae87-8855-4925-a8a0-52a1c771762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_laz  = r\"D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg.laz\"          # nube de vegetaciÃ³n\n",
    "seg_raster = r\"D:\\MODELO_3D\\arboles\\Noordereiland_height_veg_classified_ONLYveg_DEM0_75_Segments.tif\"       # raster con Segment ID (salida de SAGA)\n",
    "output_laz = r\"D:\\MODELO_3D\\arboles\\Noordereiland_segments.laz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ca90e-9c4d-4232-8837-8e0a565715ee",
   "metadata": {},
   "source": [
    "En esta fase, se cargan dos fuentes de datos:\n",
    "\n",
    "* La nube de puntos LiDAR â€” contiene coordenadas tridimensionales (X, Y, Z)\n",
    "* El raster segmentado â€” generado previamente mediante Watershed, donde cada pÃ­xel tiene un ID de segmento (Ã¡rbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2b2c15-44b6-4481-981f-87e8def2a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntos: 1292642\n",
      "TamaÃ±o raster: (1048, 1372)\n"
     ]
    }
   ],
   "source": [
    "# Leer nube LiDAR\n",
    "las = laspy.read(input_laz)\n",
    "x = las.x   # coordenadas reales (aplicando escala y offset)\n",
    "y = las.y\n",
    "\n",
    "print(\"Puntos:\", len(x))\n",
    "\n",
    "# Leer raster de segmentos\n",
    "src = rasterio.open(seg_raster)\n",
    "seg = src.read(1)              # banda con los IDs\n",
    "tfm = src.transform            # transformada afÃ­n (x,y -> fila,col)\n",
    "print(\"TamaÃ±o raster:\", seg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2332264-03f6-4d87-aa80-8e695b65d3f8",
   "metadata": {},
   "source": [
    "#### Convertir X,Y de los puntos a filas/columnas del raster\n",
    "\n",
    "Convierte las coordenadas geogrÃ¡ficas de cada punto LiDAR (X, Y) a su posiciÃ³n dentro del raster segmentado. Dado que el raster estÃ¡ organizado como una matriz (en filas y columnas), es necesario traducir las coordenadas espaciales a ubicaciones en esta matriz para saber en quÃ© pÃ­xel cae cada punto LiDAR.\n",
    "\n",
    "Una vez obtenidas las filas (rows) y columnas (cols), se crea una mÃ¡scara lÃ³gica (inside) que permite identificar Ãºnicamente los puntos que realmente caen dentro del Ã¡rea cubierta por el raster, descartando aquellos que quedan fuera de los lÃ­mites del segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1b908bb-b711-4b43-bf8c-0352381dbb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntos dentro del raster: 1292642 de 1292642\n"
     ]
    }
   ],
   "source": [
    "from rasterio.transform import rowcol\n",
    "\n",
    "# Obtener fila, columna para cada punto\n",
    "rows, cols = rowcol(tfm, x, y)\n",
    "\n",
    "rows = np.array(rows)\n",
    "cols = np.array(cols)\n",
    "\n",
    "# MÃ¡scara: puntos que caen dentro del raster\n",
    "h, w = seg.shape\n",
    "inside = (rows >= 0) & (rows < h) & (cols >= 0) & (cols < w)\n",
    "\n",
    "print(\"Puntos dentro del raster:\", inside.sum(), \"de\", len(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfe1632-83ff-4312-be44-ebc53ecbcf61",
   "metadata": {},
   "source": [
    "#### Crear vector con SegmentID por punto\n",
    "\n",
    "Se crea un vector llamado segment_id que almacena el identificador del Ã¡rbol (segmento) para cada punto de la nube LiDAR. Primero, se inicializa el vector con el valor âˆ’1, que indica que el punto no pertenece a ningÃºn segmento vÃ¡lido. Luego, solo para los puntos que sÃ­ estÃ¡n dentro del raster segmentado, se extrae el valor del pÃ­xel correspondiente y se asigna como su SegmentID. Ese nÃºmero representa el Ã¡rbol o copa a la que pertenece el punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951fc5e-bb8c-4b76-9d76-a015a7a975b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos con -1 (sin segmento)\n",
    "segment_id = np.full(len(x), -1, dtype=np.int32)\n",
    "\n",
    "# Asignar el valor SegmentID del raster a los puntos \"inside\"\n",
    "segment_id[inside] = seg[rows[inside], cols[inside]] #solo puntos que caen dentro del raster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d117d8-bd40-4a3a-9022-efc49073a10c",
   "metadata": {},
   "source": [
    "#### Guardar segment_id como nuevo atributo en el LAZ\n",
    "\n",
    "Agrega el vector segment_id como nuevo atributo dentro del archivo LiDAR. Para ello, se usa laspy, que permite manipular archivos LAS/LAZ y manejar atributos adicionales mediante ExtraBytes. Primero se define la dimensiÃ³n extra, luego se asigna el vector de IDs a cada punto, y finalmente se guarda un nuevo archivo que ya contiene la segmentaciÃ³n por Ã¡rbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6089a9e2-1ee3-4c06-a1d3-f3f00601a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado en: D:\\MODELO_3D\\arboles\\Noordereiland_segments.laz\n"
     ]
    }
   ],
   "source": [
    "from laspy import ExtraBytesParams\n",
    "\n",
    "# Definir nueva dimensiÃ³n extra\n",
    "extra = ExtraBytesParams(name=\"segment_id\", type=np.int32)\n",
    "las.add_extra_dim(extra)\n",
    "\n",
    "# Asignar los valores\n",
    "las[\"segment_id\"] = segment_id\n",
    "\n",
    "# Escribir nuevo archivo\n",
    "las.write(output_laz)\n",
    "\n",
    "print(\"Archivo guardado en:\", output_laz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec43700-c635-4cb1-b0f1-57407d38cbc1",
   "metadata": {},
   "source": [
    "## 3. DepuraciÃ³n y limpieza de segmentos\n",
    "\n",
    "Antes de extraer parÃ¡metros morfomÃ©tricos por segmento (Ã¡rbol), se aplica una fase de limpieza para descartar segmentos que no representan Ã¡rboles reales o que contienen demasiado ruido:\n",
    "\n",
    "1. **Filtros iniciales**  \n",
    "   - MÃ­nimo de 50 puntos por segmento.  \n",
    "   - Intensidad media < 100.  \n",
    "   - NÃºmero medio de retornos > 1.5.  \n",
    "   - Altura mÃ¡xima del segmento < 50 m.\n",
    "\n",
    "2. **ComprobaciÃ³n de planaridad (RANSAC)**  \n",
    "   - Se ajusta un plano con RANSAC, si la distancia media de los puntos al plano es muy pequeÃ±a (segmento casi plano),se descarta porque es probable que sea un tejado, suelo o estructura artificial.\n",
    "\n",
    "3. **EliminaciÃ³n de planos parciales y valores atÃ­picos**  \n",
    "   - Se eliminan subsecciones planas y puntos alejados (outliers) mediante funciones de limpieza (`clean_ransac`, `remove_distant_outliers`), hasta que el segmento contenga Ãºnicamente puntos que representen la estructura del Ã¡rbol.\n",
    "\n",
    "Solo los segmentos que superan todas estas comprobaciones se consideran **Ã¡rboles vÃ¡lidos** y pasan a la etapa de cÃ¡lculo de parÃ¡metros (altura, copa, radios, ratios, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7882a2-964a-4ac7-af20-cdd94a87026c",
   "metadata": {},
   "source": [
    "### ðŸ§¹3.1 Filtros iniciales y flujo de procesamiento por Ã¡rbol\n",
    "\n",
    "Se crea una funciÃ³n llamada `read_trees`, la cual recorre cada segmento (Ã¡rbol) y filtra aquellos con pocos puntos o con forma plana (posibles techos o ruido). A cada Ã¡rbol vÃ¡lido se le extraen parÃ¡metros estructurales como altura mÃ¡xima, altura de copa, base de copa, radio superior e inferior, punto de periferia y ratios entre alturas y radios. Finalmente, se almacena un arreglo con los atributos principales de cada Ã¡rbol, junto con los puntos completos para uso posterior en modelado o clasificaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46340cf0-8013-4e70-9385-ff1c485e4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trees(path, filename, outfilename):\n",
    "\n",
    "    readtime = time.perf_counter()\n",
    "    full_path = os.path.join(path, filename)\n",
    "    inFile = laspy.read(full_path)\n",
    "    \n",
    "    print (\"{}{:0.2f}{}{}\".format(\"LAZ reading time: \", time.perf_counter() - readtime, \" sec. Number of points in file: \", inFile.__len__()))\n",
    "\n",
    "    treelist = []\n",
    "    treelistfull = []\n",
    "\n",
    "    for seg_id in np.unique(inFile.segment_id):\n",
    "        for k in range(1):\n",
    "            segtime = time.perf_counter()\n",
    "            # saltar el segmento 0 (ruido / sin asignar)\n",
    "            if seg_id == 0:\n",
    "                continue\n",
    "            \"\"ConversiÃ³n a una matriz np mÃ¡s pequeÃ±a, por lo que ya no es necesario filtrar toda la nube de puntos en los siguientes pasos\".\"\n",
    "            rule = inFile.segment_id == seg_id\n",
    "            seg_array = inFile.points[rule]\n",
    "\n",
    "            \"Â¿CuÃ¡ntos puntos tiene realmente un Ã¡rbol? Esta implementaciÃ³n usa un mÃ­nimo de 50 puntos.\"\n",
    "            \n",
    "            # FILTROS INICIALES A NIVEL DE SEGMENTO\n",
    "            seg_point_count = len(seg_array)\n",
    "            if seg_point_count < 50:\n",
    "                continue\n",
    "\n",
    "            X = seg_array['X']\n",
    "            Y = seg_array['Y']\n",
    "            Z = seg_array['Z'].astype(float)  # coordenadas Z originales\n",
    "            Z_real = seg_array['Z']\n",
    "            fit_3dfier = int(np.average(Z - Z_real))\n",
    "\n",
    "            # nÃºmero mÃ­nimo de puntos \"internos\" que RANSAC debe explicar\n",
    "            avg_inliers = int(len(seg_array)/100.0*55.0)\n",
    "\n",
    "            # COMPROBACIÃ“N DE PLANARIDAD DEL SEGMENTO (RANSAC SOBRE X,Y,Z)\n",
    "            ransac = linear_model.RANSACRegressor(\n",
    "                linear_model.LinearRegression(),\n",
    "                stop_n_inliers=avg_inliers,\n",
    "                min_samples=3\n",
    "            )\n",
    "            ransac.fit(np.array((X, Y)).T, Z)\n",
    "\n",
    "            inlier_mask = ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            a = np.array((X[inlier_mask], Y[inlier_mask], Z[inlier_mask])).T\n",
    "            b = np.array((X[inlier_mask], Y[inlier_mask], ransac.predict(np.array((X[inlier_mask], Y[inlier_mask])).T))).T\n",
    "            # distancia media de los puntos reales al plano ajustado\n",
    "            avg_distance = np.average(np.sqrt(np.sum((a - b) ** 2, axis=1)))\n",
    "\n",
    "            \"\"\"Omitir si el segmento consta de un solo plano\"\"\"\n",
    "            # si la distancia media < 1 m â‡’ segmento casi plano â‡’ no se considera Ã¡rbol\n",
    "            if avg_distance < 1:\n",
    "                continue\n",
    "\n",
    "            # LIMPIEZA ADICIONAL: PLANOS PARCIALES E INTENSIDAD / RETORNOS\n",
    "            seg_indexes = np.where(inFile.segment_id == seg_id)[0]\n",
    "            return_array = inFile.num_returns[seg_indexes]\n",
    "\n",
    "            return_array, seg_array, X, Y, Z = clean_ransac(return_array, seg_array, X, Y, Z)\n",
    "            if len(return_array) == 0:\n",
    "                # This condition is met when either the avg. intensity is too high or the avg. nr of returns is too low.\n",
    "                continue\n",
    "\n",
    "            if len(X) == 0:\n",
    "                continue\n",
    "\n",
    "            seg_array, X, Y, Z = remove_distant_outliers(seg_array, X, Y, Z)\n",
    "            if len(X) == 0:\n",
    "                continue\n",
    "\n",
    "            if len(seg_array) < 10:\n",
    "                continue\n",
    "\n",
    "            \"\"\" Nueva funciÃ³n, extracciÃ³n de parÃ¡metros\"\"\"\n",
    "\n",
    "            Z = Z - fit_3dfier\n",
    "\n",
    "            max_height = np.max(Z)\n",
    "            min_height = np.min(Z)\n",
    "\n",
    "            \"\"\"Cima del Ã¡rbol: SerÃ¡ la altura mÃ¡xima o el percentil 99 de altura\"\"\"\n",
    "            tree_top = np.percentile(Z, 99)\n",
    "            if tree_top/1000.0 > 50:\n",
    "                continue\n",
    "\n",
    "            \"\"\"Base del Ã¡rbol: Cero, ya que la altura se calcula como la altura desde el suelo. Este valor debe recalcularse \n",
    "            posteriormente al valor Z original.\"\"\"\n",
    "            tree_base = np.percentile(Z, 1)\n",
    "\n",
    "            \"\"\"Base de la copa del Ã¡rbol: serÃ¡ el 1.Âº o 5.Âº percentil de altura.\"\"\"\n",
    "            tree_crown_base = np.percentile(Z, 5)\n",
    "\n",
    "            \"\"\"Punto PerifÃ©rico: SerÃ¡ el intervalo de altura donde se ubican la mayorÃ­a de los puntos.\"\"\"\n",
    "            \"\"\"Periferia Inferior y Superior: Puntos intermedios entre el Punto PerifÃ©rico y la Base y la Copa del Ãrbol, respectivamente.\"\"\"\n",
    "            division = np.linspace(min_height, max_height, num=11)\n",
    "            countlst = []\n",
    "\n",
    "            for i in range(len(division)-1):\n",
    "                division_perc = ((i+1)*10)-5.0\n",
    "                space = np.logical_and(Z >= division[i], Z < division[i+1])\n",
    "\n",
    "                # Cuando una divisiÃ³n no tiene puntos, pasa a la siguiente divisiÃ³n.\n",
    "                div_point_count = np.sum(space)\n",
    "                if div_point_count == 0:\n",
    "                    continue\n",
    "\n",
    "                center = np.average(X[space]), np.average(Y[space])\n",
    "                coords = np.vstack((X[space], Y[space])).transpose()\n",
    "                division_height = (division[i]+division[i+1])/2\n",
    "\n",
    "                radius = np.percentile(np.sqrt(np.sum((coords - center)**2, axis=1)), 99)\n",
    "                templst = [div_point_count, division_height, division_perc, center, radius, division[i], division[i+1]]\n",
    "                countlst.append(templst)\n",
    "            periphery = max(countlst)\n",
    "            periphery_lower = (periphery[1] + tree_crown_base) / 2.0\n",
    "            periphery_higher = (periphery[1] + tree_top) / 2.0\n",
    "\n",
    "            for div in countlst:\n",
    "                if div[5] <= periphery_lower <= div[6]:\n",
    "                    radius_lower = div[4]\n",
    "                    if div[0] < 5:\n",
    "                        radius_lower = False\n",
    "                if div[5] <= periphery_higher <= div[6]:\n",
    "                    radius_higher = div[4]\n",
    "                    if div[0] < 5:\n",
    "                        radius_higher = False\n",
    "            if type(radius_higher) == bool or type(radius_lower) == bool:\n",
    "                continue\n",
    "\n",
    "            \"\"\"CaracterÃ­sticas de los tipos de Ã¡rboles: relaciones entre las alturas de la periferia, los radios y\n",
    "            la copa del Ã¡rbol frente a la base de la copa.\"\"\"\n",
    "\n",
    "            height_ratio_hi_lo = periphery_higher / periphery_lower\n",
    "            height_ratio_hi_per = periphery_higher / periphery[1]\n",
    "            height_ratio_per_lo = periphery[1] / periphery_lower\n",
    "\n",
    "            radius_ratio_hi_lo = radius_higher / radius_lower\n",
    "            radius_ratio_hi_per = radius_higher / periphery[4]\n",
    "            radius_ratio_per_lo = periphery[4] / radius_lower\n",
    "\n",
    "            top_base_ratio = tree_top / tree_crown_base\n",
    "            per_height_per_radius_ratio = periphery[1] / periphery[4]\n",
    "\n",
    "            tree = [seg_id, periphery[3][0], periphery[3][1], seg_point_count, tree_base, tree_crown_base, periphery[1],\n",
    "                    periphery[4], periphery_lower, radius_lower, periphery_higher, radius_higher, tree_top,\n",
    "                    height_ratio_hi_lo, height_ratio_hi_per, height_ratio_per_lo, radius_ratio_hi_lo,\n",
    "                    radius_ratio_hi_per, radius_ratio_per_lo, top_base_ratio,\n",
    "                    np.average(seg_array['intensity']), np.average(return_array), per_height_per_radius_ratio]\n",
    "\n",
    "            treelist.append(tree)\n",
    "            treelistfull.append(seg_array.array.copy())\n",
    "            \n",
    "    if not treelist:\n",
    "        print(\"No se encontrÃ³ ningÃºn Ã¡rbol vÃ¡lido despuÃ©s de aplicar los filtros.\")\n",
    "        return None  \n",
    "        \n",
    "    print(\"ðŸŒ³ Total Ã¡rboles vÃ¡lidos encontrados:\", len(treelist))\n",
    "    \n",
    "    tree_array = np.vstack(treelist)\n",
    "\n",
    "    full_tree_array = np.concatenate(treelistfull, axis=0)\n",
    "    \n",
    "    outfilename_2 = \"{}{}\".format(outfilename, \"_Full\")\n",
    "    np.save(\"{}{}{}\".format(path, \"/Data/Temp/\", outfilename), tree_array)\n",
    "    np.save(\"{}{}{}\".format(path, \"/Data/Temp/\", outfilename_2), full_tree_array)\n",
    "\n",
    "    return tree_array\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cbb5b1-31b2-4817-8596-e43fdd123ae2",
   "metadata": {},
   "source": [
    "### ðŸ” 3.2 Limpieza de planos y outliers dentro del Ã¡rbol\n",
    "\n",
    "La funciÃ³n `clean_ransac`aplica una limpieza mÃ¡s fina a cada segmento (Ã¡rbol) usando RANSAC:\n",
    "\n",
    "1. Se seleccionan solo los puntos con un retorno (`return_array == 1`), que suelen corresponder a superficies mÃ¡s compactas (posibles planos).\n",
    "2. Se descartan segmentos con intensidad media muy alta** (> 180) o nÃºmero medio de retornos demasiado bajo** (â‰¤ 1.5), ya que probablemente no son Ã¡rboles.\n",
    "3. Si hay suficientes puntos con 1 retorno, se ajusta un plano 3D con RANSAC y se calcula la distancia media de los puntos a dicho plano:\n",
    "   - Si el plano se ajusta muy bien (distancias pequeÃ±as), se considera que esa parte del segmento es un plano (techo, estructura) y se elimina.\n",
    "   - El proceso puede repetirse recursivamente cambiando los ejes (`swap=True`) para detectar planos en otras orientaciones.\n",
    "4. Si solo hay unos pocos puntos â€œsospechososâ€ con 1 retorno, se eliminan directamente.\n",
    "5. Si no hay puntos con 1 retorno, la funciÃ³n devuelve el segmento sin cambios.\n",
    "\n",
    "El resultado son versiones filtradas de `return_array`, `seg_array`, `X`, `Y`, `Z`, con planos y outliers eliminados en la medida de lo posible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149772d6-06e8-46f6-ad37-23c3e861db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ransac(return_array, seg_array, X, Y, Z, swap=False):\n",
    "    \"\"\"\n",
    "    Limpia planos y outliers usando RANSAC sobre puntos con 1 retorno.\n",
    "    Devuelve return_array, seg_array, X, Y, Z filtrados.\n",
    "    \"\"\"\n",
    "    # Ãndices de puntos con 1 retorno\n",
    "    clean_indexes = np.where(return_array == 1)[0]\n",
    "    seg_array_low_nr = seg_array[clean_indexes]\n",
    "\n",
    "    # Filtros rÃ¡pidos por intensidad y nÂº de retornos\n",
    "    if np.average(seg_array['intensity']) > 180:\n",
    "        print(\"high intensity\", np.unique(seg_array['segment_id']), np.average(seg_array['intensity']))\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    if np.average(return_array) <= 1.5:\n",
    "        # print(\"low returns\", np.unique(seg_array['segment_id']), np.average(return_array), len(return_array))\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    # Caso 1: suficientes puntos con 1 retorno -> intentamos ajustar plano\n",
    "    if len(seg_array_low_nr) > 10:\n",
    "        # Tomar coordenadas para RANSAC\n",
    "        X_P = seg_array_low_nr['X']\n",
    "        Y_P = seg_array_low_nr['Y']\n",
    "        Z_P = seg_array_low_nr['height above ground']\n",
    "\n",
    "        # Si swap=True, cambiamos ejes para intentar mejor ajuste\n",
    "        if swap:\n",
    "            Z_P = seg_array_low_nr['Y']\n",
    "            Y_P = seg_array_low_nr['height above ground']\n",
    "            Z = seg_array['Y']\n",
    "            Y = seg_array['height above ground']\n",
    "            \n",
    "        # Ajuste de plano mediante RANSAC\n",
    "        ransac2 = linear_model.RANSACRegressor(\n",
    "            linear_model.LinearRegression(),\n",
    "            min_samples=3,\n",
    "        )\n",
    "        ransac2.fit(np.array((X_P, Y_P)).T, Z_P)\n",
    "\n",
    "        inlier_mask2 = ransac2.inlier_mask_\n",
    "        outlier_mask2 = np.logical_not(inlier_mask2)\n",
    "        \n",
    "        # Inliers usados para medir el ajuste del plano\n",
    "        X_P_I = X_P[inlier_mask2]\n",
    "        Y_P_I = Y_P[inlier_mask2]\n",
    "        Z_P_I = Z_P[inlier_mask2]\n",
    "\n",
    "        inliers = np.array((X_P_I, Y_P_I, Z_P_I)).T\n",
    "        inlier_predictions = np.array(\n",
    "            (X_P_I, Y_P_I, ransac2.predict(np.array((X_P_I, Y_P_I)).T))\n",
    "        ).T\n",
    "        \n",
    "        # Distancia media de los inliers al plano â†’ calidad del plano\n",
    "        avg_distance = np.average(np.sqrt(np.sum((inliers - inlier_predictions) ** 2, axis=1)))\n",
    "\n",
    "        # Predicciones sobre todos los puntos del Ã¡rbol\n",
    "        predictions = np.array((X, Y, ransac2.predict(np.array((X, Y)).T))).T\n",
    "        allsamples = np.array((X, Y, Z)).T\n",
    "        \n",
    "        # Distancia de cada punto al plano\n",
    "        distances = np.sqrt(np.sum(np.square(allsamples - predictions), axis=1))\n",
    "        distances2 = []\n",
    "\n",
    "        for point in allsamples:\n",
    "            mindist = np.min(np.sqrt(np.sum(np.square(inliers - point), axis=1)))\n",
    "            distances2.append(mindist)\n",
    "        distances2 = np.array(distances2)\n",
    "\n",
    "        # Si el plano ajusta bien (avg_distance pequeÃ±a) â†’ eliminar puntos cercanos a ese plano\n",
    "        if avg_distance < 100:\n",
    "            deletelist = []\n",
    "\n",
    "            # Identificar Ã­ndices de los puntos que forman el plano principal\n",
    "            for x_p, y_p, z_p in np.nditer((X_P_I, Y_P_I, Z_P_I)):\n",
    "                xi = np.where(X == x_p)[0]\n",
    "                yi = np.where(Y == y_p)[0]\n",
    "                zi = np.where(Z == z_p)[0]\n",
    "                common_idx = np.intersect1d(xi, np.intersect1d(yi, zi))\n",
    "                if common_idx.size > 0:\n",
    "                    deletelist.append(common_idx[0])\n",
    "                    \n",
    "            # MÃ¡s puntos a eliminar: cerca del plano y de los inliers\n",
    "            stuff = np.where((distances < 750) & (distances2 < 2000))[0]\n",
    "            mask_stuff = np.logical_not(np.isin(stuff, deletelist))\n",
    "\n",
    "            deletelist.extend(stuff[mask_stuff])\n",
    "            \n",
    "            # Construir mÃ¡scara inversa (puntos que se quedan)\n",
    "            mask = ~np.isin(np.arange(len(seg_array)), deletelist)\n",
    "\n",
    "            seg_array = seg_array[mask]\n",
    "            return_array = return_array[mask]\n",
    "            X = X[mask]\n",
    "            Y = Y[mask]\n",
    "            Z = Z[mask]\n",
    "            \n",
    "            # Si se eliminaron todos los puntos, el segmento deja de ser vÃ¡lido\n",
    "            if len(seg_array) == 0:\n",
    "                return [], [], [], [], []\n",
    "                \n",
    "            # Si aÃºn hay suficientes puntos, repetir limpieza con swap=True\n",
    "            if len(seg_array) > 100:   # solo si hay suficientes puntos\n",
    "                return_array, seg_array, X, Y, Z = clean_ransac(return_array, seg_array, X, Y, Z, swap=True)\n",
    "\n",
    "            return return_array, seg_array, X, Y, Z\n",
    "\n",
    "        # Si el plano no es bueno y aÃºn no hemos swapeado ejes, probar de nuevo con swap=True\n",
    "        if avg_distance >= 100 and swap is False:\n",
    "            return clean_ransac(return_array, seg_array, X, Y, Z, swap=True)\n",
    "        else:\n",
    "            if swap:\n",
    "                return return_array, seg_array, X, Z, Y\n",
    "            else:\n",
    "                return return_array, seg_array, X, Y, Z\n",
    "\n",
    "    # Caso 2: pocos puntos problemÃ¡ticos (0 < len < 10) -> borrarlos todos sin buscar matching fino\n",
    "    if 0 < len(seg_array_low_nr) < 10:\n",
    "        \"\"\"\n",
    "        Si hay muy pocos puntos con estas propiedades cuestionables,\n",
    "        elimÃ­nalos todos directamente, sin intentar planos.\n",
    "        \"\"\"\n",
    "        mask = np.ones(len(seg_array), dtype=bool)\n",
    "        mask[clean_indexes] = False # quitar todos los puntos con 1 retorno\n",
    "\n",
    "        seg_array = seg_array[mask]\n",
    "        return_array = return_array[mask]\n",
    "        X = X[mask]\n",
    "        Y = Y[mask]\n",
    "        Z = Z[mask]\n",
    "\n",
    "        if swap:\n",
    "            return return_array, seg_array, X, Z, Y\n",
    "        else:\n",
    "            return return_array, seg_array, X, Y, Z\n",
    "\n",
    "    # Caso 3: no hay puntos low_nr -> no limpiamos nada\n",
    "    if swap:\n",
    "        return return_array, seg_array, X, Z, Y\n",
    "    else:\n",
    "        return return_array, seg_array, X, Y, Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bc193-c0e1-4577-8a98-ec4242806822",
   "metadata": {},
   "source": [
    "### âš ï¸3.3 DepuraciÃ³n de valores atÃ­picos\n",
    "\n",
    "La funciÃ³n `remove_distant_outliers` elimina puntos atÃ­picos (outliers) dentro de cada Ã¡rbol usando **DBSCAN**:\n",
    "\n",
    "1. Se reconstruyen las coordenadas X, Y y la altura normalizada (Z = height above ground).\n",
    "2. Se normalizan las coordenadas y se aplica DBSCAN para detectar:\n",
    "   - Ruido (`labels == -1`): puntos muy aislados.\n",
    "   - Clusters secundarios: grupos pequeÃ±os alejados del Ã¡rbol principal.\n",
    "3. Si se detecta ruido, se prueba iterativamente con distintos valores de `eps`  \n",
    "   (0.50, 0.75, 1.0, 1.5, 2.0) para encontrar una separaciÃ³n razonable entre Ã¡rbol real y ruido.\n",
    "4. Si hay varios clusters, se conserva solo el cluster mÃ¡s grande (que se asume como el Ã¡rbol) \n",
    "   y se eliminan los demÃ¡s.\n",
    "5. Finalmente, si la cantidad de puntos eliminados es pequeÃ±a (â‰¤ 5 %), se borran del segmento y,\n",
    "   si aÃºn quedan suficientes puntos (> 50), el proceso se repite recursivamente.\n",
    "\n",
    "El resultado es un conjunto de puntos por Ã¡rbol mÃ¡s compacto y coherente, sin puntos â€œperdidosâ€ o\n",
    "clusters pequeÃ±os que podrÃ­an distorsionar las mÃ©tricas del Ã¡rbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e8fa87-08fa-493a-81f7-987265a41ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAZ reading time: 0.09 sec. Number of points in file: 1292642\n",
      "ðŸŒ³ Total Ã¡rboles vÃ¡lidos encontrados: 685\n",
      "Total Calculation time: 97.44 sec.\n"
     ]
    }
   ],
   "source": [
    "def remove_distant_outliers(seg_array, X, Y, Z):\n",
    "   \n",
    "    # Recalcular X, Y, Z desde seg_array para garantizar coherencia\n",
    "    X = seg_array['X']\n",
    "    Y = seg_array['Y']\n",
    "    Z = seg_array['height above ground']  \n",
    "\n",
    "    # Construir coordenadas\n",
    "    coords = np.vstack((X, Y, Z)).T\n",
    "    #Escalar\n",
    "    coordsnorm = StandardScaler().fit_transform(coords)\n",
    "    \n",
    "    # DBSCAN inicial: eps pequeÃ±o â†’ vecindades compactas\n",
    "    db = DBSCAN(eps=0.50, min_samples=50).fit(coordsnorm)\n",
    "    labels = db.labels_\n",
    "    nrpoints = len(seg_array)\n",
    "    remove = []\n",
    "\n",
    "    \"\"\"Eliminar ruido\"\"\"\n",
    "    #(labels == -1) ajustando eps si es necesario\n",
    "    if np.any(labels == -1):\n",
    "        remove = np.where(labels == -1)[0]\n",
    "        if len(remove) > (0.05 * nrpoints) or len(remove) == 0:\n",
    "            db = DBSCAN(eps=0.75, min_samples=50).fit(coordsnorm)\n",
    "            labels = db.labels_\n",
    "            if np.any(labels == -1):\n",
    "                remove = np.where(labels == -1)[0]\n",
    "                if len(remove) > (0.05 * nrpoints) or len(remove) == 0:\n",
    "                    db = DBSCAN(eps=1.0, min_samples=50).fit(coordsnorm)\n",
    "                    labels = db.labels_\n",
    "                    if np.any(labels == -1):\n",
    "                        remove = np.where(labels == -1)[0]\n",
    "                        if len(remove) > (0.05 * nrpoints) or len(remove) == 0:\n",
    "                            db = DBSCAN(eps=1.5, min_samples=50).fit(coordsnorm)\n",
    "                            labels = db.labels_\n",
    "                            if np.any(labels == -1):\n",
    "                                remove = np.where(labels == -1)[0]\n",
    "                                if len(remove) > (0.05 * nrpoints) or len(remove) == 0:\n",
    "                                    db = DBSCAN(eps=2.0, min_samples=50).fit(coordsnorm)\n",
    "                                    labels = db.labels_\n",
    "                                    if np.any(labels == -1):\n",
    "                                        remove = np.where(labels == -1)[0]\n",
    "\n",
    "    \"\"\"En caso de varios clÃºsteres -> Mantener solo el clÃºster mÃ¡s grande.\"\"\"\n",
    "    if len(np.unique(labels)) > 2:\n",
    "        clustercount = []\n",
    "        for i in np.unique(labels):\n",
    "            clustercount.append((len(np.where(labels == i)[0]), i))\n",
    "        keeplabel = max(clustercount)[1]\n",
    "        remove = np.where(labels != keeplabel)[0]\n",
    "\n",
    "    #Aplicar eliminaciÃ³n si la proporciÃ³n de puntos a borrar es razonable \n",
    "    if len(remove) > 0 and len(remove) <= 0.05 * nrpoints:\n",
    "        mask = ~np.isin(np.arange(len(seg_array)), remove)\n",
    "        seg_array = seg_array[mask]\n",
    "        X = X[mask]\n",
    "        Y = Y[mask]\n",
    "        Z = Z[mask]\n",
    "\n",
    "        # RecursiÃ³n SI aÃºn hay outliers y suficientes puntos\n",
    "        if len(seg_array) > 50:\n",
    "            return remove_distant_outliers(seg_array, X, Y, Z)\n",
    "            \n",
    "  # En cualquier otro caso, devuelve el segmento tal como estÃ¡\n",
    "    else:\n",
    "        return seg_array, X, Y, Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6eda5-d2e1-41e0-b44d-442516d6daee",
   "metadata": {},
   "source": [
    "Este bloque define los archivos de entrada y salida, ejecuta la funciÃ³n de procesamiento de Ã¡rboles (`read_trees`) y mide el tiempo total de cÃ¡lculo. Al finalizar, muestra por consola cuÃ¡nto tardÃ³ en procesarse toda la nube LiDAR segmentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48abd3a6-0737-4a54-bf8f-89c863884c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ruta = r\"D:\\MODELO_3D\\arboles\"      \n",
    "Nombre_entrada = \"Noordereiland_segments.laz\"\n",
    "Nombre_salida = \"Noordereiland_segments_AllFeatures\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \"\"\"Punto de ejecuciÃ³n principal.\n",
    "   Se define la ruta y los archivos de entrada y salida.\"\"\"\n",
    "    \n",
    "    starttime = time.perf_counter()\n",
    "\n",
    "    read_trees(Ruta, Nombre_entrada, Nombre_salida)\n",
    "\n",
    "    elapsed_time = time.perf_counter() - starttime\n",
    "    print(f\"Total Calculation time: {elapsed_time:.2f} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343e5ed-65ee-423e-b884-8bfd01e62c5d",
   "metadata": {},
   "source": [
    "## 4. PreparaciÃ³n del archivo para modelado y clasificaciÃ³n \n",
    "\n",
    "En la metodologÃ­a original, una vez finalizada la etapa de limpieza y parametrizaciÃ³n de los segmentos arbÃ³reos, se ejecuta un procedimiento de clasificaciÃ³n automÃ¡tica del tipo de Ã¡rbol (hoja caduca, conÃ­fera, ornamental, etc.). Esta clasificaciÃ³n se lleva a cabo mediante el entrenamiento de una red neuronal supervisada, cuyos modelos (ML_Classification_NN_Generator.py y ML_TreeType_Classifier.py) permiten predecir la clase tipolÃ³gica de nuevos Ã¡rboles detectados en la nube de puntos, con un valor asociado de probabilidad o classification certainty.\n",
    "\n",
    "Estos atributos (TreeType y Classification_Certainty) son fundamentales en el flujo original, ya que se incorporan posteriormente al archivo CityJSON como metadatos semÃ¡nticos, y ademÃ¡s permiten ajustar la representaciÃ³n geomÃ©trica del Ã¡rbol segÃºn su especie (por ejemplo, copa cÃ³nica en conÃ­feras o esfÃ©rica en caducifolios).\n",
    "\n",
    "Sin embargo, en el presente trabajo no se dispone del modelo previamente entrenado, ni de un conjunto de datos rotulados necesarios para llevar a cabo el entrenamiento supervisado. Por tanto, la etapa de clasificaciÃ³n automÃ¡tica no fue implementada.\n",
    "\n",
    "Con el objetivo de mantener la compatibilidad con la estructura de datos esperada por el script de reconstrucciÃ³n geomÃ©trica, se optÃ³ por simular la salida de dicho clasificador, sin modificar la lÃ³gica original del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fe1cc-28f5-4731-a41f-85f41d47fdb2",
   "metadata": {},
   "source": [
    "Se procediÃ³ a extender el archivo Noordereiland_segments_AllFeatures.npy, que contiene los parÃ¡metros geomÃ©tricos de cada Ã¡rbol, incorporando manualmente dos nuevas columnas:\n",
    "\n",
    "| Nombre del campo           | Valor asignado  | PropÃ³sito                                |\n",
    "| -------------------------- | --------------- | ---------------------------------------- |\n",
    "| `TreeType`                 | `\"GenericTree\"` | Simula la etiqueta de especie predicha   |\n",
    "| `Classification_Certainty` | `1.0` (o 0.8)   | Representa confianza ficticia del modelo |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0da34f2-7199-4910-96d4-3fcc45f93a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo: D:\\MODELO_3D\\arboles\\Data\\Temp\\Noordereiland_segments_AllFeatures.npy\n",
      "Shape original: (542, 23)\n",
      "Shape final (deberÃ­a ser N x 25): (542, 25)\n",
      "Guardado en: D:\\MODELO_3D\\arboles\\Data\\Temp\\Noordereiland_segments_AllFeatures_ML.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Estacion_1\\AppData\\Local\\Temp\\ipykernel_22652\\2657706181.py:19: UserWarning: Reading `.npy` or `.npz` file required additional header parsing as it was created on Python 2. Save the file again to speed up loading and avoid this warning.\n",
      "  tree_array = np.load(in_path)    # (N, 23) aprox\n"
     ]
    }
   ],
   "source": [
    "# Ruta a la carpeta raÃ­z del repositorio\n",
    "path = r\"D:\\MODELO_3D\\arboles\"   \n",
    "\n",
    "# Nombre del archivo que sale de Data_Cleaning_Parameter_Extract\n",
    "input_name = \"Noordereiland_segments_AllFeatures.npy\"\n",
    "\n",
    "# Nombre del archivo de salida (formato â€œ_MLâ€ compatible con json_writer)\n",
    "output_name = \"Noordereiland_segments_AllFeatures_ML.npy\"\n",
    "\n",
    "# Ruta completa de entrada y salida (usa la estructura Data/Temp del repo)\n",
    "in_path = os.path.join(path, \"Data\", \"Temp\", input_name)\n",
    "out_path = os.path.join(path, \"Data\", \"Temp\", output_name)\n",
    "\n",
    "print(\"Leyendo:\", in_path)\n",
    "tree_array = np.load(in_path)    # (N, 23) aprox\n",
    "\n",
    "print(\"Shape original:\", tree_array.shape)\n",
    "\n",
    "N = tree_array.shape[0]\n",
    "\n",
    "# Columna de tipo de Ã¡rbol (string)\n",
    "# Ponemos un tipo genÃ©rico para todos\n",
    "tree_type = np.full((N, 1), \"GenericTree\", dtype=object)\n",
    "# Ejemplo alternativa:\n",
    "# tree_type = np.full((N, 1), \"Coniferae\", dtype=object)\n",
    "\n",
    "# Columna de certeza de clasificaciÃ³n (float)\n",
    "certainty = np.ones((N, 1), dtype=float) * 0.9\n",
    "\n",
    "# Apilar -> ahora serÃ¡n 25 columnas (0â€“22 parÃ¡metros, 23 tipo, 24 certeza)\n",
    "output_array = np.column_stack((tree_array, tree_type, certainty))\n",
    "\n",
    "print(\"Shape final (deberÃ­a ser N x 25):\", output_array.shape)\n",
    "\n",
    "# Guardar\n",
    "np.save(out_path, output_array)\n",
    "print(\"Guardado en:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0b6fb-0bbc-4d53-a457-a78b458d4e32",
   "metadata": {},
   "source": [
    "## 5. Modelado GeomÃ©trico de Ã¡rboles\n",
    "\n",
    "En esta etapa se describen los pasos seguidos para construir los modelos 3D de Ã¡rboles en los distintos niveles de detalle (LOD). los modelos se generan siguiendo las especificaciones de CityJSON, de modo que cada Ã¡rbol se almacena como un CityObject, ya que el resultado del proceso son Ã¡rboles individuales.Todos los modelos implÃ­citos se basan en geometrÃ­as hexagonales, una decisiÃ³n tomada para reducir el nÃºmero de vÃ©rtices necesarios en comparaciÃ³n con formas mÃ¡s complejas.\n",
    "\n",
    "Para ello se crea la funciÃ³n `write_cityJSON`, la cual toma como entrada los parÃ¡metros geomÃ©tricos de cada Ã¡rbol y genera un archivo **CityJSON** con objetos del tipo `SolitaryVegetationObject`.\n",
    "\n",
    "En funciÃ³n del nivel de detalle (`lod`), se construyen:\n",
    "\n",
    "- **LOD0**: un hexÃ¡gono plano que representa la proyecciÃ³n de la copa.\n",
    "- **LOD1**: un prisma hexagonal elevado, que modela un volumen simple de copa.\n",
    "- **LOD2**: un modelo paramÃ©trico compuesto por tronco y varias â€œcoronasâ€ hexagonales que\n",
    "  describen mejor la forma de la copa.\n",
    "- **LOD3**: una geometrÃ­a envolvente basada en la nube de puntos, combinada con un tronco paramÃ©trico.\n",
    "\n",
    "El resultado se exporta en formato `.json` bajo la estructura CityJSON, incluyendo materiales para el tronco y la copa, y atributos bÃ¡sicos por Ã¡rbol (ID de segmento, nÃºmero de puntos, intensidad y nÃºmero de retornos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c059a9-6807-4753-8861-4e38585b43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                     # Medir tiempos de ejecuciÃ³n (cÃ¡lculos, loops, exportaciÃ³n)\n",
    "import json                     # Crear y guardar archivos en formato CityJSON (.json)\n",
    "import math                     # Funciones matemÃ¡ticas (senos, cosenos, radianes, etc. para hexÃ¡gonos)\n",
    "import matplotlib.pyplot as plt # VisualizaciÃ³n bÃ¡sica (grÃ¡ficos, nubes de puntos, ver formas de Ã¡rbol)\n",
    "from mpl_toolkits.mplot3d import Axes3D   # VisualizaciÃ³n 3D de nubes de puntos y modelos\n",
    "from scipy.spatial import Delaunay        # GeneraciÃ³n de triangulaciÃ³n para Alpha-shapes (LOD3)\n",
    "from scipy.spatial import ConvexHull      # CÃ¡lculo del casco convexo (ConvexHull) de copas en LOD3\n",
    "from collections import defaultdict        # GestiÃ³n eficiente de listas de triÃ¡ngulos Ãºnicos (Alpha-shapes)\n",
    "from sklearn.preprocessing import MinMaxScaler  # NormalizaciÃ³n de coordenadas (Alpha-shapes y convex hull)\n",
    "import sys                      # Manejo del sistema (control de rutas, interrupciones, debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd53d2fd-8cdf-46dd-a480-48204afd7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cityJSON(path, filename, lod, outfilename, param_filename, convex):\n",
    "    \n",
    "    # filename â†’ archivo de puntos (dict o array estructurado)\n",
    "    full_points_path = os.path.join(path, \"Data\", \"Temp\", filename)\n",
    "    tree_array = np.load(\"{}{}{}\".format(path, \"/Data/Temp/\", filename), allow_pickle=True)\n",
    "    \n",
    "    # Si viene como array de objetos, extraemos el diccionario\n",
    "    if isinstance(tree_array, np.ndarray) and tree_array.dtype == object:\n",
    "        tree_array = tree_array.item()\n",
    "\n",
    "    if param_filename:\n",
    "        param_array = np.load(f\"{path}/Data/Temp/{param_filename}\", allow_pickle=True)\n",
    "    jsondict = {\n",
    "        \"type\": \"CityJSON\",\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    "    jsondict['CityObjects'] = {}\n",
    "    jsondict['vertices'] = []\n",
    "\n",
    "    vcounter = 0\n",
    "\n",
    "    jsondict['appearance'] = {\n",
    "        \"materials\": [\n",
    "            {\n",
    "                \"name\": \"TreeTrunk\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.6, 0.4, 0.1],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"GenericTreeCrown\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.41, 0.61, 0.35],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Yellowish\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.85, 0.85, 0.56],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"MossyGreen\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.48, 0.54, 0.23],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"BlueishGreen\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.35, 0.40, 0.31],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"VomitGreen\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.58, 0.60, 0.38],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Grayish\",\n",
    "                \"ambientIntensity\": 0.2000,\n",
    "                \"diffuseColor\": [0.72, 0.75, 0.67],\n",
    "                \"shininess\": 0.2,\n",
    "                \"transparency\": 0.0,\n",
    "                \"isSmooth\": False\n",
    "            }\n",
    "\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Escritor para LOD, 0, 1 y 2\n",
    "    if lod != 3:\n",
    "        for tree in tree_array:\n",
    "            jsondict['CityObjects'][tree[0]] = {\n",
    "                \"type\": \"SolitaryVegetationObject\",\n",
    "            }\n",
    "\n",
    "            starttime = time.perf_counter()\n",
    "\n",
    "            \"\"\"Crear vÃ©rtices para el modelo de Ã¡rbol\"\"\"\n",
    "            \"\"\"Parametros\"\"\"\n",
    "\n",
    "            x = float(tree[1]) / 1000\n",
    "            y = float(tree[2]) / 1000\n",
    "            z_b = float(tree[4]) / 1000\n",
    "            z_c = float(tree[5]) / 1000\n",
    "            z_p = float(tree[6]) / 1000\n",
    "            r_p = float(tree[7]) / 1000\n",
    "            z_pl = float(tree[8]) / 1000\n",
    "            r_pl = float(tree[9]) / 1000\n",
    "            z_ph = float(tree[10]) / 1000\n",
    "            r_ph = float(tree[11]) / 1000\n",
    "            z_t = float(tree[12]) / 1000\n",
    "            t = math.radians(60)\n",
    "\n",
    "            \n",
    "            colorvalue = 3\n",
    "\n",
    "            \"\"\"LOD0: HexÃ¡gono parametrizado\"\"\"\n",
    "            if lod == 0:\n",
    "\n",
    "                \"\"\"Centro, Altura de la base\"\"\"\n",
    "                v1 = [x, y, z_b]\n",
    "\n",
    "                \"\"\"Periferia\"\"\"\n",
    "                v2 = [x - r_p, y, z_b]\n",
    "                v3 = [x - (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_b]\n",
    "                v4 = [x + (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_b]\n",
    "                v5 = [x + r_p, y, z_b]\n",
    "                v6 = [x + (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_b]\n",
    "                v7 = [x - (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_b]\n",
    "\n",
    "                boundaries = []\n",
    "                values = []\n",
    "\n",
    "                \"\"\"Crear Ã­ndices para el modelo de Ã¡rbol\"\"\"\n",
    "                \"\"\"Base del tronco del Ã¡rbol\"\"\"\n",
    "                for i in range(1, 7):\n",
    "                    if i != 6:\n",
    "                        boundaries.append([[vcounter, vcounter + i + 1, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter, vcounter + i - 5, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                for i in range(7):\n",
    "                    jsondict['vertices'].append(\n",
    "                        list(np.around(eval(\"{}{}\".format(\"v\", i+1)), decimals=2))\n",
    "                    )\n",
    "\n",
    "                              \"\"\"\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"TreeType\": tree[23],\n",
    "                    \"Classification_Certainty\": tree[24],\n",
    "                    \"Point Count\": tree[3],\n",
    "                    \"Height Crown Base\": z_c,\n",
    "                    \"Periphery Height\": z_p,\n",
    "                    \"Periphery Radius\": r_p,\n",
    "                    \"Lower Periphery Height\": z_pl,\n",
    "                    \"Lower Periphery Radius\": r_pl,\n",
    "                    \"Higher Periphery Height\": z_ph,\n",
    "                    \"Higher Periphery Radius\": r_ph,\n",
    "                    \"Tree Top\": z_t,\n",
    "                    \"Ratio Height High + Low\": tree[13],\n",
    "                    \"Ratio Height High + Periphery\": tree[14],\n",
    "                    \"Ratio Height Periphery + Low\": tree[15],\n",
    "                    \"Ratio Radius High + Low\": tree[16],\n",
    "                    \"Ratio Radius High + Periphery\": tree[17],\n",
    "                    \"Ratio Radius Periphery + Low\": tree[18],\n",
    "                    \"Ratio Height Tree Top + Crown Base\": tree[19],\n",
    "                    \"Average Intensity\": tree[20],\n",
    "                    \"Average Number of Returns\": tree[21],\n",
    "                    \"Ratio Periphery Height + Periphery Radius\": tree[22]\n",
    "                }\n",
    "                \"\"\"\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"Segment ID\": int(tree[0]),\n",
    "                    \"Point Count\": int(tree[3]),\n",
    "                    \"Average Intensity\": float(tree[20]),\n",
    "                    \"Average Number of Returns\": float(tree[21])\n",
    "                }\n",
    "\n",
    "\n",
    "                jsondict['CityObjects'][tree[0]]['geometry'] = [{\n",
    "                    \"type\": \"MultiSurface\",\n",
    "                    \"lod\": lod,\n",
    "                    \"boundaries\": boundaries,\n",
    "                    \"material\": {\n",
    "                        \"visual\": {\n",
    "                            \"values\": values\n",
    "                        },\n",
    "                    },\n",
    "                }]\n",
    "\n",
    "                vcounter += 7\n",
    "\n",
    "\n",
    "            \"\"\"LOD1: HexÃ¡gono elevado parametrizado\"\"\"\n",
    "            if lod == 1:\n",
    "                \"\"\"Centro, Altura de la base\"\"\"\n",
    "                v1 = [x, y, z_b]\n",
    "\n",
    "                \"\"\"LÃ­mite inferior\"\"\"\n",
    "                v2 = [x - r_p, y, z_b]\n",
    "                v3 = [x - (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_b]\n",
    "                v4 = [x + (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_b]\n",
    "                v5 = [x + r_p, y, z_b]\n",
    "                v6 = [x + (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_b]\n",
    "                v7 = [x - (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_b]\n",
    "\n",
    "                \"\"\"LÃ­mite superior\"\"\"\n",
    "                v8 = [x - r_p, y, z_t]\n",
    "                v9 = [x - (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_t]\n",
    "                v10 = [x + (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_t]\n",
    "                v11 = [x + r_p, y, z_t]\n",
    "                v12 = [x + (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_t]\n",
    "                v13 = [x - (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_t]\n",
    "\n",
    "                \"\"\"Copa del Ã¡rbol\"\"\"\n",
    "                v14 = [x, y, z_t]\n",
    "\n",
    "                boundaries = []\n",
    "                values = []\n",
    "\n",
    "                \"\"\"Crear Ã­ndices para el modelo de Ã¡rbol\"\"\"\n",
    "                \"\"\"HexÃ¡gono elevado en tierra\"\"\"\n",
    "                for i in range(1, 7):\n",
    "                    if i != 6:\n",
    "                        boundaries.append([[vcounter, vcounter + i, vcounter + i + 1]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter, vcounter + i, vcounter + i - 5]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                \"\"\"Lados hexagonales elevados\"\"\"\n",
    "                for i in range(1, 7):\n",
    "                    if i != 6:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                \"\"\"Copa de Ã¡rbol hexagonal elevada\"\"\"\n",
    "                for i in range(7, 13):\n",
    "                    if i != 12:\n",
    "                        boundaries.append([[vcounter + 13, vcounter + i + 1, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + 13, vcounter + i - 5, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                for i in range(14):\n",
    "                    jsondict['vertices'].append(\n",
    "                        list(np.around(eval(\"{}{}\".format(\"v\", i + 1)), decimals=2))\n",
    "                    )\n",
    "\n",
    "                \"\"\"\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"TreeType\": tree[23],\n",
    "                    \"Classification_Certainty\": tree[24],\n",
    "                    \"Point Count\": tree[3],\n",
    "                    \"Height Crown Base\": z_c,\n",
    "                    \"Periphery Height\": z_p,\n",
    "                    \"Periphery Radius\": r_p,\n",
    "                    \"Lower Periphery Height\": z_pl,\n",
    "                    \"Lower Periphery Radius\": r_pl,\n",
    "                    \"Higher Periphery Height\": z_ph,\n",
    "                    \"Higher Periphery Radius\": r_ph,\n",
    "                    \"Tree Top\": z_t,\n",
    "                    \"Ratio Height High + Low\": tree[13],\n",
    "                    \"Ratio Height High + Periphery\": tree[14],\n",
    "                    \"Ratio Height Periphery + Low\": tree[15],\n",
    "                    \"Ratio Radius High + Low\": tree[16],\n",
    "                    \"Ratio Radius High + Periphery\": tree[17],\n",
    "                    \"Ratio Radius Periphery + Low\": tree[18],\n",
    "                    \"Ratio Height Tree Top + Crown Base\": tree[19],\n",
    "                    \"Average Intensity\": tree[20],\n",
    "                    \"Average Number of Returns\": tree[21],\n",
    "                    \"Ratio Periphery Height + Periphery Radius\": tree[22]\n",
    "                }\n",
    "                \"\"\"\n",
    "\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"Segment ID\": int(tree[0]),\n",
    "                    \"Point Count\": int(tree[3]),\n",
    "                    \"Average Intensity\": float(tree[20]),\n",
    "                    \"Average Number of Returns\": float(tree[21])\n",
    "                }\n",
    "\n",
    "                jsondict['CityObjects'][tree[0]]['geometry'] = [{\n",
    "                    \"type\": \"MultiSurface\",\n",
    "                    \"lod\": lod,\n",
    "                    \"boundaries\": boundaries,\n",
    "                    \"material\": {\n",
    "                        \"visual\": {\n",
    "                            \"values\": values\n",
    "                        },\n",
    "                    },\n",
    "                }]\n",
    "\n",
    "                vcounter += 14\n",
    "\n",
    "            \"\"\"LOD2: Modelo de Ã¡rbol parametrizado\"\"\"\n",
    "            if lod == 2:\n",
    "                # Ajuste del tronco en LOD2\n",
    "                height = z_t - z_b\n",
    "                if height <= 0:\n",
    "                # si los parÃ¡metros vienen mal, lo saltamos\n",
    "                    continue\n",
    "\n",
    "                # Tronco llega al 40% de la altura del Ã¡rbol\n",
    "                z_c = z_b + 0.55 * height\n",
    "\n",
    "                # Radio del tronco proporcional a la copa\n",
    "                # 25% del radio de copa, mÃ­nimo 0.15 m (15 cm)\n",
    "                r_t = max(0.25 * r_p, 0.15)  \n",
    "\n",
    "                \"\"\"Centro, Altura de la base\"\"\"\n",
    "                v1 = [x, y, z_b]\n",
    "\n",
    "                \"\"\"Tronco, Tierra\"\"\"\n",
    "                v2 = [x - r_t, y, z_b]\n",
    "                v3 = [x - (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_b]\n",
    "                v4 = [x + (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_b]\n",
    "                v5 = [x + r_t, y, z_b]\n",
    "                v6 = [x + (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_b]\n",
    "                v7 = [x - (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_b]\n",
    "\n",
    "                \"\"\"Base de la corona\"\"\"\n",
    "                v8 = [x - r_t, y, z_c]\n",
    "                v9 = [x - (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_c]\n",
    "                v10 = [x + (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_c]\n",
    "                v11 = [x + r_t, y, z_c]\n",
    "                v12 = [x + (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_c]\n",
    "                v13 = [x - (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_c]\n",
    "\n",
    "                \"\"\"LÃ­mite inferior de la periferia\"\"\"\n",
    "                v14 = [x - r_pl, y, z_pl]\n",
    "                v15 = [x - (math.cos(t) * r_pl), y + (math.sin(t) * r_pl), z_pl]\n",
    "                v16 = [x + (math.cos(t) * r_pl), y + (math.sin(t) * r_pl), z_pl]\n",
    "                v17 = [x + r_pl, y, z_pl]\n",
    "                v18 = [x + (math.cos(t) * r_pl), y - (math.sin(t) * r_pl), z_pl]\n",
    "                v19 = [x - (math.cos(t) * r_pl), y - (math.sin(t) * r_pl), z_pl]\n",
    "\n",
    "                \"\"\"Periferia\"\"\"\n",
    "                v20 = [x - r_p, y, z_p]\n",
    "                v21 = [x - (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_p]\n",
    "                v22 = [x + (math.cos(t) * r_p), y + (math.sin(t) * r_p), z_p]\n",
    "                v23 = [x + r_p, y, z_p]\n",
    "                v24 = [x + (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_p]\n",
    "                v25 = [x - (math.cos(t) * r_p), y - (math.sin(t) * r_p), z_p]\n",
    "                \n",
    "                # Exagerar copa ligeramente para que sea mÃ¡s visible\n",
    "                z_ph = z_b + (z_ph - z_b) * 1.15  # eleva copa alta\n",
    "                z_t  = z_b + (z_t - z_b) * 1.20   # sube la punta del Ã¡rbol\n",
    "\n",
    "                \"\"\"LÃ­mite superior de la periferia\"\"\"\n",
    "                v26 = [x - r_ph, y, z_ph]\n",
    "                v27 = [x - (math.cos(t) * r_ph), y + (math.sin(t) * r_ph), z_ph]\n",
    "                v28 = [x + (math.cos(t) * r_ph), y + (math.sin(t) * r_ph), z_ph]\n",
    "                v29 = [x + r_ph, y, z_ph]\n",
    "                v30 = [x + (math.cos(t) * r_ph), y - (math.sin(t) * r_ph), z_ph]\n",
    "                v31 = [x - (math.cos(t) * r_ph), y - (math.sin(t) * r_ph), z_ph]\n",
    "\n",
    "                \"\"\"Copa del Ã¡rbol\"\"\"\n",
    "                v32 = [x, y, z_t]\n",
    "\n",
    "                for i in range(32):\n",
    "                    jsondict['vertices'].append(\n",
    "                        list(np.around(eval(\"{}{}\".format(\"v\", i+1)), decimals=2))\n",
    "                    )\n",
    "\n",
    "                boundaries = []\n",
    "                values = []\n",
    "\n",
    "                \"\"\"Crear Ã­ndices para el modelo de Ã¡rbol\"\"\"\n",
    "                \"\"\"Base del tronco del Ã¡rbol\"\"\"\n",
    "                for i in range(1, 7):\n",
    "                    if i != 6:\n",
    "                        boundaries.append([[vcounter, vcounter + i, vcounter + i + 1]])\n",
    "                        values.append(0)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter, vcounter + i, vcounter + i - 5]])\n",
    "                        values.append(0)\n",
    "                \"\"\"Tronco de Ã¡rbol\"\"\"\n",
    "                for i in range(1, 7):\n",
    "                    if i != 6:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                        values.append(0)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                        values.append(0)\n",
    "\n",
    "                \"\"\"Periferia inferior\"\"\"\n",
    "                for i in range(7, 13):\n",
    "                    if i != 12:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                \"\"\"Periferia\"\"\"\n",
    "                for i in range(13, 19):\n",
    "                    if i != 18:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                \"\"\"Periferia superior\"\"\"\n",
    "                for i in range(19, 25):\n",
    "                    if i != 24:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                        values.append(colorvalue)\n",
    "                \"\"\"Copa del Ã¡rbol\"\"\"\n",
    "                for i in range(25, 31):\n",
    "                    if i != 30:\n",
    "                        boundaries.append([[vcounter + 31, vcounter + i + 1, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "                    else:\n",
    "                        boundaries.append([[vcounter + 31, vcounter + i - 5, vcounter + i]])\n",
    "                        values.append(colorvalue)\n",
    "\n",
    "                \"\"\"\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"TreeType\": tree[23],\n",
    "                    \"Classification_Certainty\": tree[24],\n",
    "                    \"Point Count\": tree[3],\n",
    "                    \"Height Crown Base\": z_c,\n",
    "                    \"Periphery Height\": z_p,\n",
    "                    \"Periphery Radius\": r_p,\n",
    "                    \"Lower Periphery Height\": z_pl,\n",
    "                    \"Lower Periphery Radius\": r_pl,\n",
    "                    \"Higher Periphery Height\": z_ph,\n",
    "                    \"Higher Periphery Radius\": r_ph,\n",
    "                    \"Tree Top\": z_t,\n",
    "                    \"Ratio Height High + Low\": tree[13],\n",
    "                    \"Ratio Height High + Periphery\": tree[14],\n",
    "                    \"Ratio Height Periphery + Low\": tree[15],\n",
    "                    \"Ratio Radius High + Low\": tree[16],\n",
    "                    \"Ratio Radius High + Periphery\": tree[17],\n",
    "                    \"Ratio Radius Periphery + Low\": tree[18],\n",
    "                    \"Ratio Height Tree Top + Crown Base\": tree[19],\n",
    "                    \"Average Intensity\": tree[20],\n",
    "                    \"Average Number of Returns\": tree[21],\n",
    "                    \"Ratio Periphery Height + Periphery Radius\": tree[22]\n",
    "                }\n",
    "                \"\"\"\n",
    "\n",
    "                jsondict['CityObjects'][tree[0]]['attributes'] = {\n",
    "                    \"Segment ID\": int(tree[0]),\n",
    "                    \"Point Count\": int(tree[3]),\n",
    "                    \"Average Intensity\": float(tree[20]),\n",
    "                    \"Average Number of Returns\": float(tree[21])\n",
    "                }\n",
    "\n",
    "                jsondict['CityObjects'][tree[0]]['geometry'] = [{\n",
    "                    \"type\": \"MultiSurface\",\n",
    "                    \"lod\": lod,\n",
    "                    \"boundaries\": boundaries,\n",
    "                    \"material\": {\n",
    "                        \"visual\": {\n",
    "                            \"values\": values\n",
    "                        },\n",
    "                    },\n",
    "                }]\n",
    "\n",
    "                vcounter += 32\n",
    "\n",
    "        with open(\"{}{}{}\".format(path, \"/Data/Output/\", outfilename), 'w') as json_file:\n",
    "            json.dump(jsondict, json_file, indent=2)\n",
    "\n",
    "        print (time.perf_counter() - starttime)\n",
    "        \n",
    "    # Escritor para LODs 3.0 y 3.1\n",
    "    if lod == 3:\n",
    "        starttime = time.perf_counter()\n",
    "        skipped_trees = 0\n",
    "    \n",
    "        max_trees = 50  # ðŸ‘ˆ prueba con 20, 50, 100...\n",
    "        max_points_per_tree = 50\n",
    "        \n",
    "        unique_ids = np.unique(tree_array['segment_id'])\n",
    "    \n",
    "        for idx_seg, seg_id in enumerate(unique_ids):\n",
    "            if idx_seg >= max_trees:\n",
    "                break\n",
    "\n",
    "        for seg_id in np.unique(tree_array['segment_id']):\n",
    "            rule = tree_array['segment_id'] == seg_id\n",
    "\n",
    "            # puntos del Ã¡rbol actual\n",
    "            tree = tree_array[rule]\n",
    "        \n",
    "            if tree.shape[0] > max_points_per_tree:\n",
    "                idx = np.random.choice(tree.shape[0], max_points_per_tree, replace=False)\n",
    "                tree = tree[idx]\n",
    "\n",
    "            # buscar parÃ¡metros de ese Ã¡rbol en param_array\n",
    "            index_param = np.where(np.array(param_array[:, 0], dtype=float) == seg_id)[0]\n",
    "            if len(index_param) == 0:\n",
    "                continue\n",
    "                \n",
    "            tree_param = np.array(param_array[index_param][0, :23], dtype=float)\n",
    "            tree_type = \"Unknown\"\n",
    "            type_certainty = float(\"nan\")\n",
    "\n",
    "\n",
    "            if len(tree) < 50:\n",
    "                continue\n",
    "             \n",
    "            colorvalue = 1\n",
    "\n",
    "            \"\"\" Genera materials.\n",
    "            yellowtrees = [\"Ailanthus\", \"Amelanchier\", \"Prunus\"]\n",
    "            mossytrees = [\"Alnus\", \"Corylus\", \"Pyrus\", \"Robinia\", \"Styphnolobium\"]\n",
    "            blueishtrees = [\"Fagus\", \"Catalpa\"]\n",
    "            vomittrees = [\"Ginkgo\", \"Pinus\"]\n",
    "            grayishtrees = [\"Liriodendron\", \"Malus\", \"Sorbus\"]\n",
    "\n",
    "            if tree_type in yellowtrees:\n",
    "                colorvalue = 2\n",
    "            if tree_type in mossytrees:\n",
    "                colorvalue = 3\n",
    "            if tree_type in blueishtrees:\n",
    "                colorvalue = 4\n",
    "            if tree_type in vomittrees:\n",
    "                colorvalue = 5\n",
    "            if tree_type in grayishtrees:\n",
    "                colorvalue = 6\n",
    "            \"\"\"\n",
    "\n",
    "            if tree_type == \"Coniferae\":\n",
    "                colorvalue = 5\n",
    "            x = tree['X'] / 1000.0\n",
    "            y = tree['Y'] / 1000.0\n",
    "            z = tree['height above ground'] / 1000.0  \n",
    "            Z_real = tree['Z'] / 1000.0\n",
    "\n",
    "            fit_3dfier = int(np.average(z - Z_real))\n",
    "            z = z - fit_3dfier\n",
    "            \n",
    "            # Exagerar suavemente la copa en LOD3 (20% mÃ¡s alta)\n",
    "            z_min = z.min()\n",
    "            z = z_min + (z - z_min) * 1.20   # prueba con 1.15, 1.2, 1.3 segÃºn lo que veas\n",
    "            \n",
    "            pos = np.array((x, y, z)).T\n",
    "\n",
    "            \"\"\"Alpha shapes\"\"\"\n",
    "            if not convex:\n",
    "                convex = False\n",
    "                alpha = 0.5\n",
    "\n",
    "                xnorm = MinMaxScaler().fit_transform(x.reshape(-1, 1))\n",
    "                ynorm = MinMaxScaler().fit_transform(y.reshape(-1, 1))\n",
    "                znorm = MinMaxScaler().fit_transform(z.reshape(-1, 1))\n",
    "                posnorm = np.array((xnorm, ynorm, znorm)).T[0]\n",
    "\n",
    "                # Halla el radio de la circunsfera.\n",
    "                # Por definiciÃ³n, el radio de la esfera que encaja dentro del tetraÃ©drico debe ser menor que el valor alfa.\n",
    "\n",
    "                tetrapos = np.take(posnorm, tetra.simplices, axis=0)\n",
    "                normsq = np.sum(tetrapos ** 2, axis=2)[:, :, None]\n",
    "                ones = np.ones((tetrapos.shape[0], tetrapos.shape[1], 1))\n",
    "                a = np.linalg.det(np.concatenate((tetrapos, ones), axis=2))\n",
    "                Dx = np.linalg.det(np.concatenate((normsq, tetrapos[:, :, [1, 2]], ones), axis=2))\n",
    "                Dy = -np.linalg.det(np.concatenate((normsq, tetrapos[:, :, [0, 2]], ones), axis=2))\n",
    "                Dz = np.linalg.det(np.concatenate((normsq, tetrapos[:, :, [0, 1]], ones), axis=2))\n",
    "                c = np.linalg.det(np.concatenate((normsq, tetrapos), axis=2))\n",
    "\n",
    "                r = np.sqrt((Dx ** 2 + Dy ** 2 + Dz ** 2) - (4 * a * c)) / (2 * np.abs(a))\n",
    "\n",
    "                # Encuentra tetraÃ©dricos\n",
    "                tetras = tetra.simplices[r < alpha, :]\n",
    "\n",
    "                # triÃ¡ngulos\n",
    "                TriComb = np.array([(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)])\n",
    "                Triangles = tetras[:, TriComb].reshape(-1, 3)\n",
    "                Triangles = np.sort(Triangles, axis=1)\n",
    "\n",
    "                # Eliminar los triÃ¡ngulos que aparecen dos veces, porque estÃ¡n dentro de las formas.\n",
    "                TrianglesDict = defaultdict(int)\n",
    "                for tri in Triangles:\n",
    "                    TrianglesDict[tuple(tri)] += 1\n",
    "                Triangles = np.array([tri for tri in TrianglesDict if TrianglesDict[tri] == 1])\n",
    "                # bordes\n",
    "                EdgeComb = np.array([(0, 1), (0, 2), (1, 2)])\n",
    "\n",
    "                Edges = Triangles[:, EdgeComb].reshape(-1, 2)\n",
    "                Edges = np.sort(Edges, axis=1)\n",
    "                Edges = np.unique(Edges, axis=0)\n",
    "\n",
    "                Vertices = np.unique(Edges)\n",
    "\n",
    "\n",
    "                verts = np.hstack((np.where(Triangles[0][0] == Vertices)[0],\n",
    "                                   np.where(Triangles[0][1] == Vertices)[0],\n",
    "                                   np.where(Triangles[0][2] == Vertices)[0]))\n",
    "\n",
    "                for triangle in Triangles[1:]:\n",
    "                    verts = np.vstack((verts, np.hstack((np.where(triangle[0] == Vertices)[0],\n",
    "                                                         np.where(triangle[1] == Vertices)[0],\n",
    "                                                         np.where(triangle[2] == Vertices)[0]))))\n",
    "                unsorted_triangles = verts\n",
    "                vertices = pos[Vertices]\n",
    "                boundaries = []\n",
    "                values = []\n",
    "\n",
    "            \"\"\"Convex Hulls\"\"\"\n",
    "            if convex:\n",
    "                convexpoints = ConvexHull(pos).vertices\n",
    "                convdelly = Delaunay(pos[convexpoints])\n",
    "                unsorted_triangles = convdelly.convex_hull\n",
    "                vertices = pos[convexpoints]\n",
    "                boundaries = []\n",
    "                values = []\n",
    "\n",
    "            \"\"\"Encuentra las medias aristas entre triÃ¡ngulos en una envoltura convexa y hace que solo las caras miren hacia afuera\"\"\"\n",
    "            starttriangle = unsorted_triangles[0]\n",
    "            neighborlist = []\n",
    "            boundary_array = None\n",
    "\n",
    "            sorted_triangles = sort_triangles(unsorted_triangles, starttriangle, neighborlist, boundary_array)\n",
    "            if type(sorted_triangles) == bool:\n",
    "                # Caso: Uno o mÃ¡s triÃ¡ngulos en la malla tienen mÃ¡s de 3 triÃ¡ngulos vecinos, esto no deberÃ­a suceder\n",
    "                skipped_trees += 1\n",
    "                continue\n",
    "\n",
    "            ccw_sorted_triangles = ccw_orientation(sorted_triangles, vertices)\n",
    "            ccw_sorted_triangles = ccw_sorted_triangles + vcounter\n",
    "\n",
    "            for boundary in ccw_sorted_triangles:\n",
    "                boundaries.append([boundary.tolist()])\n",
    "                values.append(colorvalue)\n",
    "\n",
    "            vcounter += len(vertices)\n",
    "\n",
    "            \"\"\"AÃ±adir tronco de Ã¡rbol\"\"\"\n",
    "\n",
    "              # Alturas reales del Ã¡rbol\n",
    "            z_min = Z_real.min()\n",
    "            z_max = Z_real.max()\n",
    "            height = z_max - z_min\n",
    "\n",
    "            if height <= 0:\n",
    "                # Ã¡rbol raro, lo saltamos\n",
    "                skipped_trees += 1\n",
    "                continue\n",
    "\n",
    "            # Centro en planta del Ã¡rbol (XY promedio)\n",
    "            x_center = float(x.mean())\n",
    "            y_center = float(y.mean())\n",
    "\n",
    "            # Radio \"copa\" aproximado como el radio mÃ¡ximo en XY\n",
    "            dx = x - x_center\n",
    "            dy = y - y_center\n",
    "            radial_dist = np.sqrt(dx**2 + dy**2)\n",
    "            r_crown = np.percentile(radial_dist, 90)  # radio de copa tÃ­pico\n",
    "\n",
    "            # Definimos el tronco:\n",
    "            z_b = z_min                       # base del tronco (suelo)\n",
    "            z_c = z_min + 0.55 * height        # tronco llega al 40% de la altura\n",
    "            r_t = max(0.25 * r_crown, 0.15)   # radio del tronco = 25% del radio de copa, min 15 cm\n",
    "\n",
    "            x = x_center\n",
    "            y = y_center\n",
    "            t = math.radians(60)\n",
    "\n",
    "            \"\"\"Centro, Suelo\"\"\"\n",
    "            v1 = [x, y, z_b]\n",
    "\n",
    "            \"\"\"Tronco, Suelo\"\"\"\n",
    "            v2 = [x - r_t, y, z_b]\n",
    "            v3 = [x - (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_b]\n",
    "            v4 = [x + (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_b]\n",
    "            v5 = [x + r_t, y, z_b]\n",
    "            v6 = [x + (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_b]\n",
    "            v7 = [x - (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_b]\n",
    "\n",
    "            \"\"\"Parte superior del tronco\"\"\"\n",
    "            v8 = [x - r_t, y, z_c]\n",
    "            v9 = [x - (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_c]\n",
    "            v10 = [x + (math.cos(t) * r_t), y + (math.sin(t) * r_t), z_c]\n",
    "            v11 = [x + r_t, y, z_c]\n",
    "            v12 = [x + (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_c]\n",
    "            v13 = [x - (math.cos(t) * r_t), y - (math.sin(t) * r_t), z_c]\n",
    "\n",
    "            \"\"\"Centro, parte superior del tronco\"\"\"\n",
    "            v14 = [x, y, z_c]\n",
    "\n",
    "            \"\"\"LÃ­mites del tronco del Ã¡rbol\"\"\"\n",
    "            boundaries2 = []\n",
    "            values2 = []\n",
    "\n",
    "            \"\"\"Crear Ã­ndices para el modelo de tronco de Ã¡rbol implÃ­cito\"\"\"\n",
    "            \"\"\"HexÃ¡gono elevado en tierra\"\"\"\n",
    "            for i in range(1, 7):\n",
    "                if i != 6:\n",
    "                    boundaries2.append([[vcounter, vcounter + i, vcounter + i + 1]])\n",
    "                    values2.append(0)\n",
    "                else:\n",
    "                    boundaries2.append([[vcounter, vcounter + i, vcounter + i - 5]])\n",
    "                    values2.append(0)\n",
    "\n",
    "            \"\"\"Lados hexagonales elevados\"\"\"\n",
    "            for i in range(1, 7):\n",
    "                if i != 6:\n",
    "                    boundaries2.append([[vcounter + i, vcounter + i + 6, vcounter + i + 7, vcounter + i + 1]])\n",
    "                    values2.append(0)\n",
    "                else:\n",
    "                    boundaries2.append([[vcounter + i, vcounter + i + 6, vcounter + i + 1, vcounter + i - 5]])\n",
    "                    values2.append(0)\n",
    "\n",
    "            \"\"\"Copa de Ã¡rbol hexagonal elevada\"\"\"\n",
    "            for i in range(7, 13):\n",
    "                if i != 12:\n",
    "                    boundaries2.append([[vcounter + 13, vcounter + i + 1, vcounter + i]])\n",
    "                    values2.append(0)\n",
    "                else:\n",
    "                    boundaries2.append([[vcounter + 13, vcounter + i - 5, vcounter + i]])\n",
    "                    values2.append(0)\n",
    "\n",
    "            vcounter += 14\n",
    "            boundaries.extend(boundaries2)\n",
    "            values.extend(values2)\n",
    "\n",
    "            jsondict['CityObjects'][str(seg_id)] = {\n",
    "                \"type\": \"SolitaryVegetationObject\",\n",
    "            }\n",
    "\n",
    "            jsondict['CityObjects'][str(seg_id)]['attributes'] = {\n",
    "                \"TreeType\": tree_type,\n",
    "                \"Classification_Certainty\": type_certainty,\n",
    "                \"Point Count\": tree_param[3],\n",
    "                \"Average Intensity\": np.around(tree_param[20], decimals=2),\n",
    "                \"Average Number of Returns\": np.around(tree_param[21], decimals=2)\n",
    "            }\n",
    "\n",
    "            jsondict['CityObjects'][str(seg_id)]['geometry'] = [{\n",
    "                \"type\": \"MultiSurface\",\n",
    "                \"lod\": lod,\n",
    "                \"boundaries\": boundaries,\n",
    "                \"material\": {\n",
    "                    \"visual\": {\n",
    "                        \"values\": values\n",
    "                    },\n",
    "                },\n",
    "            }]\n",
    "\n",
    "            vertices = np.around(vertices, decimals=2).tolist()\n",
    "\n",
    "            \"\"\"Vertices for Alpha-Shapes or ConvexHulls\"\"\"\n",
    "            for i in vertices:\n",
    "                jsondict['vertices'].append(i)\n",
    "\n",
    "            \"\"\"Vertices para Troncos de Ã¡rboles\"\"\"\n",
    "            for i in range(14):\n",
    "                jsondict['vertices'].append(\n",
    "                    list(np.around(eval(\"{}{}\".format(\"v\", i + 1)), decimals=2))\n",
    "                )\n",
    "        # Eliminar atributos para reducir el peso del archivo\n",
    "        for cid in jsondict['CityObjects']:\n",
    "            jsondict['CityObjects'][cid].pop(\"attributes\", None)\n",
    "\n",
    "        # Redondear coordenadas a 2 decimales (reduce tamaÃ±o SIN daÃ±ar forma)\n",
    "        jsondict['vertices'] = [\n",
    "            [round(v[0], 2), round(v[1], 2), round(v[2], 2)] for v in jsondict['vertices']]\n",
    "    \n",
    "        # prettyprint\n",
    "        with open(\"{}{}{}\".format(path, \"/Data/Output/\", outfilename), 'w') as json_file:\n",
    "            json.dump(jsondict, json_file, indent=2)\n",
    "\n",
    "        # compact\n",
    "        # with open(\"{}{}{}\".format(path, \"/Data/Output/FinalOutput/\", outfilename), 'w') as json_file:\n",
    "        #     json.dump(jsondict, json_file)\n",
    "\n",
    "        print (\"This many trees were not included due to a too low alpha value:\", skipped_trees)\n",
    "        print (time.perf_counter() - starttime)\n",
    "\n",
    "def sort_triangles(unsorted_triangles, starttriangle, neighborlist, boundary_array, boundary_array_cond=False):\n",
    "    if len(neighborlist) > 0:\n",
    "        neighborlist = neighborlist[1:]\n",
    "\n",
    "    i = unsorted_triangles[:, 0]\n",
    "    j = unsorted_triangles[:, 1]\n",
    "    k = unsorted_triangles[:, 2]\n",
    "\n",
    "    l = starttriangle[0]\n",
    "    m = starttriangle[1]\n",
    "    n = starttriangle[2]\n",
    "\n",
    "    neighbors = unsorted_triangles[np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(\n",
    "        np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(\n",
    "            np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(\n",
    "\n",
    "                np.logical_and(np.logical_and(l == i, m == j), n != k),\n",
    "                np.logical_and(np.logical_and(l == i, m != j), n == k)),\n",
    "                np.logical_and(np.logical_and(l != i, m == j), n == k)),\n",
    "\n",
    "                np.logical_and(np.logical_and(l == i, m == k), n != j)),\n",
    "                np.logical_and(np.logical_and(l == i, m != k), n == j)),\n",
    "                np.logical_and(np.logical_and(l != i, m == k), n == j)),\n",
    "\n",
    "            np.logical_and(np.logical_and(l == j, m == k), n != i)),\n",
    "            np.logical_and(np.logical_and(l == j, m != k), n == i)),\n",
    "            np.logical_and(np.logical_and(l != j, m == k), n == i)),\n",
    "\n",
    "            np.logical_and(np.logical_and(l == j, m == i), n != k)),\n",
    "            np.logical_and(np.logical_and(l == j, m != i), n == k)),\n",
    "            np.logical_and(np.logical_and(l != j, m == i), n == k)),\n",
    "\n",
    "        np.logical_and(np.logical_and(l == k, m == i), n != j)),\n",
    "        np.logical_and(np.logical_and(l == k, m != i), n == j)),\n",
    "        np.logical_and(np.logical_and(l != k, m == i), n == j)),\n",
    "\n",
    "        np.logical_and(np.logical_and(l == k, m == j), n != i)),\n",
    "        np.logical_and(np.logical_and(l == k, m != j), n == i)),\n",
    "        np.logical_and(np.logical_and(l != k, m == j), n == i)\n",
    "    )]\n",
    "\n",
    "    if boundary_array_cond == False:\n",
    "        unsorted_triangles = np.delete(unsorted_triangles, np.where((starttriangle == unsorted_triangles).all(axis=1))[0], axis=0)\n",
    "        boundary_array = np.array(starttriangle)\n",
    "        boundary_array_cond = True\n",
    "\n",
    "    if len(neighbors) > 3:\n",
    "        return False\n",
    "    for neighbor in neighbors:\n",
    "        if np.ndim(boundary_array) == 2:\n",
    "            ax_var = 1\n",
    "        else:\n",
    "            ax_var = None\n",
    "        if not (starttriangle == boundary_array).all(axis=ax_var).any():\n",
    "            boundary_array = np.vstack((boundary_array, starttriangle))\n",
    "        if not (neighbor == boundary_array).all(axis=ax_var).any():\n",
    "            if (np.flip(neighbor) == boundary_array).all(axis=ax_var).any():\n",
    "                continue\n",
    "            o, p, q = starttriangle[0], starttriangle[1], starttriangle[2]\n",
    "            r, s, t = neighbor[0], neighbor[1], neighbor[2]\n",
    "            if np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(np.logical_or(\n",
    "                    np.logical_and(np.logical_and(o == r, p == s), q != t),\n",
    "                    np.logical_and(np.logical_and(o == r, p != s), q == t)),\n",
    "                    np.logical_and(np.logical_and(o != r, p == s), q == t)),\n",
    "\n",
    "                    np.logical_and(np.logical_and(o == s, p == t), q != r)),\n",
    "                    np.logical_and(np.logical_and(o == s, p != t), q == r)),\n",
    "                    np.logical_and(np.logical_and(o != s, p == t), q == r)),\n",
    "\n",
    "                    np.logical_and(np.logical_and(o == t, p == r), q != s)),\n",
    "                    np.logical_and(np.logical_and(o == t, p != r), q == s)),\n",
    "                    np.logical_and(np.logical_and(o != t, p == r), q == s)):\n",
    "                boundary_array = np.vstack((boundary_array, np.flip(neighbor)))\n",
    "                neighborlist.append(np.flip(neighbor))\n",
    "            else:\n",
    "                boundary_array = np.vstack((boundary_array, neighbor))\n",
    "                neighborlist.append(neighbor)\n",
    "\n",
    "    if len(neighborlist) > 0:\n",
    "        next_starttriangle = neighborlist[0]\n",
    "        return sort_triangles(unsorted_triangles, next_starttriangle, neighborlist, boundary_array, boundary_array_cond)\n",
    "    else:\n",
    "        sorted_triangles = boundary_array\n",
    "        return sorted_triangles\n",
    "\n",
    "def ccw_orientation(boundaries, vertices):\n",
    "    triangles = vertices[boundaries]\n",
    "    maxdex = np.argmax(np.average(triangles[:, :, 2], axis=1))\n",
    "    bottom_triangle = triangles[maxdex]\n",
    "\n",
    "    v0 = bottom_triangle[0]\n",
    "    v1 = bottom_triangle[1]\n",
    "    v2 = bottom_triangle[2]\n",
    "\n",
    "    normal = np.cross(v1 - v0, v2 - v1)\n",
    "    if normal[2] > 0:\n",
    "        return boundaries\n",
    "    else:\n",
    "        return np.flip(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edd985-ee93-4290-a0f5-808d08795e7c",
   "metadata": {},
   "source": [
    "Este bloque principal permite seleccionar el nivel de detalle (LOD 0â€“3) con el que se construirÃ¡ el modelo geomÃ©trico de Ã¡rboles en CityJSON. Dependiendo del LOD, se utilizan diferentes fuentes de datos: los modelos implÃ­citos (LOD 0, 1 y 2) se generan a partir de parÃ¡metros geomÃ©tricos como altura, radio de copa o intensidad media; mientras que el LOD 3 usa directamente los puntos LiDAR segmentados por Ã¡rbol (segment_id) para construir una geometrÃ­a realista mediante Convex Hull o Alpha-Shapes. Finalmente, se ejecuta la funciÃ³n write_cityJSON() para generar y guardar el modelo CityJSON resultante.\n",
    "\n",
    "| LOD | Forma de Ã¡rbol                               | Tipo de datos usados                   |\n",
    "| --- | -------------------------------------------- | -------------------------------------- |\n",
    "| 0   | HexÃ¡gono plano                               | Solo parÃ¡metros bÃ¡sicos                |\n",
    "| 1   | HexÃ¡gono extruido (volumen simple)           | Altura y radio                         |\n",
    "| 2   | Modelo paramÃ©trico de copa y tronco          | ParÃ¡metros geomÃ©tricos del Ã¡rbol       |\n",
    "| 3   | GeometrÃ­a real (puntos LiDAR + Alpha Shapes) | Usa nube de puntos con `segment_id` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4351ef1c-c837-4755-b8f3-4a94d251acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This many trees were not included due to a too low alpha value: 0\n",
      "7.71840259997407\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os, sys\n",
    "\n",
    "    path = r\"D:\\MODELO_3D\\arboles\"\n",
    "\n",
    "    param_filename = False\n",
    "    lod = 3       #LOD seleccionado\n",
    "    convex = True\n",
    "\n",
    "    if lod == 0:\n",
    "        filename = \"Noordereiland_segments_AllFeatures.npy\"        # features por Ã¡rbol\n",
    "        param_filename = None\n",
    "        convex = False\n",
    "        outfilename = \"Noordereiland_Classified_lod0.json\"\n",
    "\n",
    "    elif lod == 1:\n",
    "        filename = \"Noordereiland_segments_AllFeatures.npy\"\n",
    "        param_filename = None\n",
    "        convex = False\n",
    "        outfilename = \"Noordereiland_Classified_lod1.json\"\n",
    "\n",
    "    elif lod == 2:\n",
    "        filename = \"Noordereiland_segments_AllFeatures.npy\"\n",
    "        param_filename = None\n",
    "        convex = False\n",
    "        outfilename = \"Noordereiland_Classified_lod2.json\"\n",
    "\n",
    "    elif lod == 3:\n",
    "        # ðŸ‘‡ aquÃ­ va el LOD 3:\n",
    "        filename = \"Noordereiland_segments_AllFeatures_full.npy\"   # puntos con segment_id\n",
    "        param_filename = \"Noordereiland_segments_AllFeatures.npy\"  # features por Ã¡rbol\n",
    "        convex = True # o False si quieres alpha-shape en vez de convex hull\n",
    "        outfilename = \"Noordereiland_Classified_lod3C.json\"\n",
    "\n",
    "    sys.setrecursionlimit(10000)\n",
    "    write_cityJSON(path, filename, lod, outfilename, param_filename, convex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55f192-d506-4f1b-a911-edd2dfdce044",
   "metadata": {},
   "source": [
    "## 6. VisualizaciÃ³n\n",
    "\n",
    "Para la visualizaciÃ³n interactiva de los archivos generados en formato .cityjson, se utilizÃ³ la plataforma web CityJSON Ninja, disponible en:\n",
    "\n",
    "ðŸ”— https://ninja.cityjson.org/\n",
    "\n",
    "CityJSON Ninja es un visor oficial desarrollado por la iniciativa CityJSON/CityGML, que permite cargar y explorar modelos 3D directamente en el navegador sin necesidad de instalar software adicional. Esta herramienta es particularmente Ãºtil para inspeccionar la correcta construcciÃ³n de los objetos, revisar la integridad geomÃ©trica (vertices, boundaries, MultiSurface), verificar la orientaciÃ³n de las caras y validar el nivel de detalle (LOD) asignado a cada Ã¡rbol.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b763e80-c0df-4291-a7dd-be23cadc31de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lidar_metrics",
   "language": "python",
   "name": "lidar_metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
